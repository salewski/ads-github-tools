#!/bin/bash -

# Copyright (c) 2016, 2017 Alan D. Salewski <salewski@att.net>
#
#     This program is free software; you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation; either version 2 of the License, or
#     (at your option) any later version.
#
#     This program is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program; if not, write to the Free Software Foundation,
#     Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301,, USA.

# ads-github-fetch-all-upstreams: Make an authenticated call to the GitHub API
# (using curl) to obtain a list of all of my repositories. For each, if a
# local directory (beneath the current location) is found that matches the
# repo name (and that directory is a git working directory, and it has a
# remote named 'upstream' defined), then this program will change into the
# local working directory for that repo and run a 'git fetch upstream'
# command.
#
# All requests are made over HTTPS.
#
# Authentication
# ==============
# No authentication data is used directly; the curl(1) '-n' (--netrc) option
# is used, so the user is expected to have his GitHub credentials stored in a
# ~/.netrc file. For details on setting that up, see curl(1) and
# netrc(5). Note that curl will not use the ~/.netrc file if the permissions
# allow reading by group or other.
#
# HINT: The relevant line ~/.netrc file content should have the form:
#
#     machine api.github.com login YOUR_USER_NAME password YOUR_GITHUB_PASSWORD
#
# CAVEAT: Use of the netrc(5) configuration means that this tool is ultimately
# using username/password with the GitHub API. Though all communication is
# conducted over HTTPS (so is encrypted "on the wire"), this authentication
# mechanism allows this tool to access the full power of the GitHub API.
#
# DO NOT USE THIS TOOL UNLESS YOU TRUST THAT IT IS NOT ABUSING THIS TRUST.
#
# Use of the OAuth mechanisms would allow for the access needed by this
# program while preventing use of the access it does not need. I'm not
# worrying about that at the moment though, as I'm the only user, and I expect
# that anything more elaborate should probably be integrated into a more
# featureful tool (such as 'git-hub', which already has OAuth support).
#
# Motivation
# ==========
# With even a relatively small number of GitHub repositories, keeping local
# trees up to date with upstreams can be a chore. This tool performs one piece
# of automation that can contribute to a solution.
#
# TODO
# ====
#
#     When this program was initially introduced, the author scribbled notes
#     in this comments section to remind himself about bugs to be fixed and
#     potential new features that might be useful. Both are now tracked in the
#     project's GitHub "issues" page here:
#
#         https://github.com/salewski/ads-github-tools/issues
#
#
# See Also:
# =========
#
#     * The 'Repos' section of the GitHub API (v3)
#       https://developer.github.com/v3/repos/
#
#     * The 'git-hub' tool:
#       https://github.com/sociomantic-tsunami/git-hub

declare -r PROG='ads-github-fetch-all-upstreams'

set -o pipefail

# declare -r MAINTAINER='@DFLT_MAINTAINER_FULL@'
declare -r MAINTAINER='@PACKAGE_BUGREPORT@'  # value filtered-in at build time

declare -r VERSION='@VERSION@'  # value filtered-in at build time

declare -r gl_const_build_date='@BUILD_DATE@'  # value filtered-in at build time
declare -r gl_const_release="${VERSION}  (built: ${gl_const_build_date})"
# declare -r gl_const_release="${VERSION}"

BE_VERBOSE=false # info-level output; override with one '-v' opt

# This one implies BE_VERBOSE, too
DEBUGGING=false  # debug-level output; override with two '-v' opts


# GitHub issue #28: Unset GREP_OPTIONS to make grep(1) behavior predictable.
#
# This only has an effect if the grep program in use is GNU grep; other grep
# implementations did not recognize or alter their behavior based on the
# 'GREP_OPTIONS' variable. GNU grep prior to version 2.11 (~2014-11) would
# append values from this variable to the command line, which would make
# behavior of our invocations in the current program unpredictable. Versions
# of GNU grep 2.11 or newer no longer behave that way, but do emit a warning
# on stderr about the change in behavior.
#
# Unsetting GREP_OPTIONS here has the effect of making our grep invocations
# predictable (when older versions of GNU grep are in use) and also of
# suppressing the spurious warning:
#
#     grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
#
# when newer versions of GNU grep are in use.
#
# See: https://github.com/salewski/ads-github-tools/issues/28
#
unset GREP_OPTIONS


# If specified, the '--clone-if-missing' command line option directs this
# program to clone any repository from GitHub where the local git working
# directory is missing. The default behavior (when that option is not
# specified) is to just operate on the working directories that are present.
#
# Note that we invoke the 'git-hub' tool (via 'git hub clone') to implement
# this feature. That means that we'll not only clone the repository if it is
# missing, but we'll also have the 'upstream' remote set up (if the repo is a
# fork of another repo). This works regardless of whether or not the working
# directory was present when this command was invoked.
#
DO_CLONE_IF_NOT_PRESENT=false


# The default behavior of the program is to operate only on working
# directories that are present ("operate only on these" semantics).
#
# Sometimes you want exactly the opposite behavior, though ("fetch all the new
# stuff" semantics). Our '--missing-only' command line option allows the user
# to request that behavior.
#
# See also: https://github.com/salewski/ads-github-tools/issues/22
#
FETCH_ONLY_MISSING=false


# It may be the case that we have cloned one of our repositories manually, but
# for whatever reason have not set up the 'upstream' remote to point to the
# parent GitHub repository from which ours was cloned.
#
# By default, this program will not perform any action on any such working
# directories. But if the '-u' ('--upstream-remote-if-missing') option is
# specified, we will take action to setup a git remote named "upstream" using
# the parent repo's clone url.
#
DO_CREATE_UPSTREAM_REMOTE_IF_NOT_PRESENT=false


# Folks using GitHub Enterprise might access their API at a different
# location, so we parameterize the base URL for the GitHub API. MAKE SURE THIS
# URL INDICATES HTTPS (not just HTTP -- you do not want your HTTP Basic Auth
# credentials being transmitted in cleartext!).
#
# This is NOT declared read-only here because there is some minor fixup that
# we attempt so users do not need to be concerned with whether or not the URL
# ends with a slash. For our purposes we need the value to end with a slash,
# and will add a slash to the end if it is not specified here.
#
declare    gl_const_github_api_base_url='https://api.github.com/'

# We'll help future-proof this program by explicitly requesting version 3 of
# the GitHub API (although it is the default at the time of writing
# (2016-04)).
#
declare -r gl_const_http_accept_github_version='Accept: application/vnd.github.v3+json'


# By default we'll use the external programs found at configure-time (values
# are filtered-in here at build time). But we allow the user to override any
# particular tool by setting an environment variable named after the tool
# (with hyphen chars changed to underscores).

CAT_PROG="${CAT:-@CAT@}"

CURL_PROG="${CURL:-@CURL_PROG@}"

ECHO_PROG="${ECHO:-@ECHO_PROG@}"

EXPR_PROG="${EXPR:-@EXPR_PROG@}"

GIT_PROG="${GIT:-@GIT_PROG@}"

# FIXME: How to make this selectable? Would need to influence git's search
#        path to find the specified version of the tool, but how to do that
#        without changing PATH?
#
# git-hub - command line GitHub API tool; works as 'git' subcommand if found
#           on PATH
#           see: https://github.com/sociomantic-tsunami/git-hub
#                https://www.kernel.org/pub/software/scm/git/docs/howto/new-command.html
#
# GIT_HUB_PROG="${GIT_HUB:-@GIT_HUB_PROG@}"
GIT_HUB_PROG='git-hub'

HEAD_PROG="${HEAD:-@HEAD_PROG@}"

# jq - command line JSON parser and manipulation language
#      see: https://github.com/stedolan/jq
#
JQ_PROG="${JQ:-@JQ_PROG@}"

SED_PROG="${SED:-@SED@}"

TR_PROG="${TR:-@TR_PROG@}"

XARGS_PROG="${XARGS:-@XARGS_PROG@}"

declare -a NEEDED_EXTERNAL_PROGS=(
    "${CAT_PROG}"
    "${CURL_PROG}"
    "${ECHO_PROG}"
    "${EXPR_PROG}"
    "${HEAD_PROG}"
    "${JQ_PROG}"
    "${GIT_PROG}"
    "${GIT_HUB_PROG}"
    "${SED_PROG}"
    "${TR_PROG}"
    "${XARGS_PROG}"
)


declare -a F_CLEANUP_HOOK_NAMES=()

function f_add_cleanup_hook_name () {
    F_CLEANUP_HOOK_NAMES+=( $1 );
}


function f_cleanup () {

    if test ${#F_CLEANUP_HOOK_NAMES[@]} -eq 0; then
        # No cleanup hooks, so nothing to do
        return
    fi

    local cleanup_hook
    local idx

    let idx=${#F_CLEANUP_HOOK_NAMES[@]}-1

    # Note that we're running the cleanup hooks in opposite order from which
    # they were installed.
    #
    while test $idx -ge 0; do

        cleanup_hook=${F_CLEANUP_HOOK_NAMES[$idx]}

        if $BE_VERBOSE; then
            printf "${PROG} (info): running cleanup hook: [%s]\n" "${cleanup_hook}" 1>&2
        fi

        test -n "$cleanup_hook" && eval "$cleanup_hook"

        let idx=$idx-1
    done
}

function f_cleanup_and_die () {
    f_cleanup
    exit 1
}

trap 'printf "$PROG (warn): HUP signal caught; bailing out\n"  1>&2; f_cleanup_and_die' HUP
trap 'printf "$PROG (warn): INT signal caught; bailing out\n"  1>&2; f_cleanup_and_die' INT
trap 'printf "$PROG (warn): QUIT signal caught; bailing out\n" 1>&2; f_cleanup_and_die' QUIT
trap 'printf "$PROG (warn): TERM signal caught; bailing out\n" 1>&2; f_cleanup_and_die' TERM

trap 'f_cleanup' EXIT



f_print_help () {

    "${CAT_PROG}" <<EOF
usage: $PROG [OPTION...] [REPO...]
Invokes 'git fetch upstream' for all of the user's GitHub repos that are
present. With appropriate options, will clone some or all missing repos and
set up the 'upstream' remote.

Mandatory arguments to long options are mandatory for short options too.

  -h, --help                        Print this help message on stdout
  -V, --version                     Print the version of the program on stdout
  -c, --clone-if-missing            Use git-hub(1) to clone your missing repos from GitHub
  -m, --missing-only                Operate on (clone) only repos that are missing locally (implies '-c')
  -u, --upstream-remote-if-missing  Setup 'upstream' remote in existing repo working dirs, if missing

  -v, --verbose                     Print program progress messages on stderr. Specify multiple
                                      times to increase verbosity: info, debug, and tracing (set -x)

      --                            Signals the end of options and disables further options processing.

Report bugs to $MAINTAINER.
EOF
}

f_print_version () {
    "${CAT_PROG}" <<EOF
${PROG} ${gl_const_release}
Copyright (C) 2016, 2017 Alan D. Salewski
License GPLv2+: GNU GPL version 2 or later <http://gnu.org/licenses/gpl.html>.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by Alan D. Salewski.
EOF
}

# Invoked by our accumulating '-v' (--verbose) option. Increases the program
# output verbosity level by "one stage".
#
# If we have not yet increased the verbosity, then enables info-level output
# ($BE_VERBOSE).
#
# If we are currently at info-level verbosity, then enables debug-level output
# ($DEBUGGING).
#
# If we are currently at debug-level verbosity, then enables trace-level
# output (set -x).
#
# If we are already at trace-level verbosity, then this function has no effect
# (is effectively a NOOP).
#
f_maybe_increase_verbosity () {

    if $BE_VERBOSE; then

        # We are (at least) at info-level verbosity currently.
        if $DEBUGGING; then
            # We are (at least) at debug-level verbosity currently.

            case $- in
                *x* )
                    : $PROG \(trace: $LINENO\): tracing already enabled
                    ;;
                * )
                    printf "${PROG} (debug): additional verbosity requested; enabling trace-level output\n" 1>&2
                    set -x
                    ;;
            esac
        else
            printf "${PROG} (info): additional verbosity requested; enabling debug-level output\n" 1>&2
            DEBUGGING=true
        fi
    else
        printf "${PROG} (info): verbose output requested; enabling info-level output\n" 1>&2
        BE_VERBOSE=true
    fi
}

# Makes a HTTP HEAD request to the GitHub service to obtain pagination
# information for pulling all /user/repos data in the minimal number of
# service calls (that is, within the service restriction of 100 repos per
# response "page").
#
# Upon success, emits on stdout the number of "pages" that need to be
# requested.
#
# Recall that the first page is one, not zero.
#
f_get_gh_user_repos_pagination_count_or_die () {

    # Pagination: 
    #
    # HTTP/1.1 200 OK
    # ...
    # Link: <https://api.github.com/user/repos?per_page=100&page=2>; rel="next", <https://api.github.com/user/repos?per_page=100&page=4>; rel="last"

    t_head_response=$( "${CURL_PROG}" "${MY_CURL_OPTS[@]}" \
                            --head               \
                            "${MY_GITHUB_REPOS_URL}" \
                       | "${TR_PROG}" -d '\r' )

    if test $? -ne 0; then
        # Hopefully curl printed something meaningful to stderr here...
        printf "${PROG} (error): was unable to obtain pagination info for repos; bailing out\n" 1>&2
        exit 1
    fi

    # From RFC 7230:
    #
    #     3.1.2.  Status Line
    #
    #        The first line of a response message is the status-line, consisting
    #        of the protocol version, a space (SP), the status code, another
    #        space, a possibly empty textual phrase describing the status code,
    #        and ending with CRLF.
    #
    #          status-line = HTTP-version SP status-code SP reason-phrase CRLF
    #
    #        The status-code element is a 3-digit integer code describing the
    #        result of the server's attempt to understand and satisfy the client's
    #        corresponding request.  The rest of the response message is to be
    #        interpreted in light of the semantics defined for that status code.
    #        See Section 6 of [RFC7231] for information about the semantics of
    #        status codes, including the classes of status code (indicated by the
    #        first digit), the status codes defined by this specification,
    #        considerations for the definition of new status codes, and the IANA
    #        registry.
    #
    #          status-code    = 3DIGIT
    #
    #        The reason-phrase element exists for the sole purpose of providing a
    #        textual description associated with the numeric status code, mostly
    #        out of deference to earlier Internet application protocols that were
    #        more frequently used with interactive text clients.  A client SHOULD
    #        ignore the reason-phrase content.
    #
    #          reason-phrase  = *( HTAB / SP / VCHAR / obs-text )
    #
    # Note that we're following Postel's Prescription to an extent in being
    # lenient about whether or not there is more than a single whitespace
    # token between fields.
    #
    t_http_head_stat_and_label=$(echo "${t_head_response}" | "${HEAD_PROG}" -n 1 | "${SED_PROG}" -n -e '/^HTTP[/]/ { s#^HTTP/[^[:space:]]\{1,\}[[:space:]]\{1,\}\([[:digit:]]\{3\}[[:space:]]\{1,\}.*\)#\1#p;q }')
    if test -z "${t_http_head_stat_and_label}"; then
        printf "${PROG} (error): was unable to extract HTTP status code from responses; bailing out\n    Full HTTP response headers:\n%s\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi

    if $DEBUGGING; then
        printf "${PROG} (debug): HTTP status and label for pagination info: %s\n" "${t_http_head_stat_and_label}" 1>&2
    fi

    t_http_head_stat=$(  echo "${t_http_head_stat_and_label}" | "${SED_PROG}" -e 's#^\([[:digit:]]\{3\}\)[[:space:]]\{1,\}.*#\1#')
    t_http_head_label=$( echo "${t_http_head_stat_and_label}" | "${SED_PROG}" -e 's#^[[:digit:]]\{3\}[[:space:]]\{1,\}\([[:space:][:alnum:][:punct:]]*\)$#\1#')

    if $DEBUGGING; then
        printf "${PROG} (debug): HTTP status for pagination info: %s\n" "${t_http_head_stat}"  1>&2
        printf "${PROG} (debug): HTTP label for pagination info: %s\n"  "${t_http_head_label}" 1>&2
    fi

    if test -z "${t_http_head_stat}"; then
        printf "${PROG} (error): was unable to determine HTTP status code of pagination info request for repo; bailing out\n" 1>&2
        exit 1
    fi

    # Slice off leading zeros in bogon HTTP response code. Belt AND suspenders...
    #
    t_http_head_stat=$((10#$t_http_head_stat))

    if test $t_http_head_stat -lt 100; then
        # We'll include the full response line to help in troubleshooting. In
        # the worst case scenario we will learn that we mis-parsed it somehow,
        # which is a really a win in the long term.
        printf "${PROG} (error): received bogon HTTP status line with response code less than 100 (\"%s\"); bailing out\n" "${t_http_head_stat_and_label}" 1>&2
        exit 1
    fi

    # Oh hell, if we're gonna check the lower bound, then we're boning it if
    # we don't also check the upper bound...
    if test $t_http_head_stat -gt 599; then
        printf "${PROG} (error): received bogon HTTP status line with response code greater than 599 (\"%s\"); bailing out\n" "${t_http_head_stat_and_label}" 1>&2
        exit 1
    fi

    # So we know that the HTTP status code is somewhere between 100 and 599...

    if test $t_http_head_stat -ge 100 \
    && test $t_http_head_stat -lt 200; then
        printf "${PROG} (error): program does not directly grok HTTP 1xx \"Informational\" status codes; bailing out\n    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi

    if test $t_http_head_stat -ge 300 \
    && test $t_http_head_stat -lt 400; then
        printf "${PROG} (error): program does not directly grok HTTP 3xx \"Redirection\" status codes; bailing out\n"\
"    If you encounter this error, please submit a bug report; real-world need is likely to get it fixed.\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi

    if test $t_http_head_stat -ge 400 \
    && test $t_http_head_stat -lt 500; then
        printf "${PROG} (error): program received a HTTP 4xx \"Client Error\" status codes; bailing out\n"\
"    If you encounter this error, please submit a bug report; it suggests there is a problem with the\n"\
"    way in which the program is formulating requests to the upstream GitHub service.\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi

    if test $t_http_head_stat -ge 500 \
    && test $t_http_head_stat -lt 600; then
        printf "${PROG} (error): program received a HTTP 5xx \"Server Error\" status codes; bailing out\n"\
"    If you encounter this error, it suggests there is a problem with the upstream GitHub service;\n"\
"    please wait a while and try your request later.\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi

    # Internal sanity check
    if test $t_http_head_stat -ge 200 \
    && test $t_http_head_stat -lt 300; then :; else
        printf "${PROG} (bug): internal check failed. Expected that we received a 2xx \"Successful\" HTTP status code, but really have: \"%s\"; bailing out.\n"\
"    If you encounter this error, there is a serious bug with this program; please submit a bug report.\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi

    # So we know that the HTTP status code is somewhere between 200 and 299;
    # we're good (probably).

    # FIXME: This will break if the 'Link:' header content spans multiple
    #        lines (which is legit; see RFC 2616 section 4.2 "Message
    #        Headers").

    # Let's find the 'Link: ' header...
    t_http_head_link=$(echo "${t_head_response}" | grep '^Link:[[:space:]]')
    if test $? -ne 0; then

        # It's not necessarily an error if the 'Link:' header is not
        # present. That will happen for resources that do not require any
        # pagination. So we'll examine the individual exit status codes from
        # our pipeline; if grep exited with status 1, it means the header was
        # not found. If it exited with 2 it indicates an error (such as a
        # malformed regex).
        #
        if test "${PIPESTATUS[0]}" -eq 0 \
        && test "${PIPESTATUS[1]}" -eq 1; then
            # We'll emit 1 as the count of pages needed
            printf "1\n"
            return  # success
        fi

        # Hopefully grep emitted something helpful on stderr already if we're
        # falling through here...

        printf "${PROG} (error): was error while attempting to locate HTTP \"Link:\" header in HEAD response; no pagination data available; bailing out\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi

    # After the 'Link: ' header label, we expect the content to contain a
    # comma-space-separated list of values in the form:
    #
    #     <url>; rel="foo", <url>; rel="bar"
    #
    # Example:
    #
    #     Link: <https://api.github.com/user/repos?per_page=100&page=2>; rel="next", <https://api.github.com/user/repos?per_page=100&page=4>; rel="last"
    #
    # We'll look for the rel="last" entry, which should be present even when
    # it's URL value would be the same as the rel="next" entry. The first
    # 'sed' invocation lifts out the URL from the rel="last" entry, and the
    # second then extracts the number of the last page from the 'page=N'
    # parameter.
    #
    t_last_page_number=$( echo "${t_http_head_link}" \
                          | "${SED_PROG}" -n -e 's#.*\([<][^>]\{1,\}[>]\)[[:space:]]*[;][^,]*rel="last"#\1#p' \
                          | "${SED_PROG}" -n -e 's#.*[?&]page=\([[:digit:]]\{1,\}\)[^[:digit:]]#\1#p' )
    if test $? -ne 0; then
        printf "${PROG} (error): was error while attempting to parse last page number from HTTP \"Link:\" header in HEAD response; bailing out\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi
    if test -z "${t_last_page_number}"; then
        printf "${PROG} (error): extracted empty value for last page number from HTTP \"Link:\" header in HEAD response; bailing out\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | "${SED_PROG}" -e 's/^/        /')" 1>&2
        exit 1
    fi

    printf "%s\n" "${t_last_page_number}"
    return  # success
}


pos_last_plus_one=$(( $# + 1 ))

# Each value is one or zero, which indicates whether or not the option is
# expected to have an argument.
#
declare -A longopt_spec=(
    ['help']=0      # -h
    ['version']=0   # -V

    ['clone-if-missing']=0            # -c
    ['missing-only']=0                # -m
    ['upstream-remote-if-missing']=0  # -u
    ['verbose']=0                     # -v
)

# internal sanity check
for one_key in "${!longopt_spec[@]}"; do
    one_val=${longopt_spec[${one_key}]}
    if [[ $one_val =~ ^[01]$ ]]; then :; else
        printf "${PROG} (BUG) [line $LINENO]: value (%s) for longopt key '%s' must be either 0 or 1; bailing out\n" \
               "${one_val}" "${one_key}" 1>&2
        exit 1
    fi
done

if test $# -gt 0; then

    # Using getopts in "silent mode". Note that adding '-' to the optstring allows us to
    # process GNU-style long-form options; that option is specified to take an argument to
    # cause getopts to place whatever follows the second '-' character into OPTARG.
    #
    # Note that getopts will automatically stop processing options upon encountering
    # '--', but we still need to deal with the pathological form --=BLAH (no option name,
    # just a value using the equals-sign syntax).
    #
    while getopts ':-:hcmuVv' opt
    do
        : $PROG \(trace: $LINENO\): opt is: $opt

        if test "${opt}" = '-'; then

            # Intercepting processing of long-form option. This conditional
            # block will set up the 'opt', 'OPTARG', and 'OPTIND' variables for
            # the code that follows, just as if getopts had the capability to
            # process long-form options.

            # OPTARG here is one of:
            #
            #     =BLAH    (which means user specified '--=BLAH')
            # or:
            #     foo
            # or:
            #     foo=FOOVAL

            if [[ ${OPTARG} =~ .*=.* ]]; then

                : $PROG \(trace: $LINENO\): OPTARG is name=value style

                # Keep everything up to the first '=' sign. Note that if the
                # option was specified as: --foo=FOOVAL, then $opt here will be
                # 'foo' (no hyphen chars).
                opt=${OPTARG/=*/}
                : $PROG \(trace: $LINENO\): opt is: $opt

                : $PROG \(trace: $LINENO\): a long option name must be at least two characters in length
                if test ${#opt} -le 1; then
                    printf "${PROG} (error): invalid long option '%s'; bailing out\n" "${opt}" 1>&2
                    f_print_help 1>&2
                    exit 1
                fi

                t_exists=false
                for one_key in "${!longopt_spec[@]}"; do
                    if test "${opt}" = "${one_key}"; then
                        t_exists=true
                        break
                    fi
                done

                : $PROG \(trace: $LINENO\): a long option name must be one that the program is expecting
                if $t_exists; then :; else

                    printf "${PROG} (error): invalid long option '%s'; bailing out\n" "${opt}" 1>&2
                    f_print_help 1>&2
                    exit 1
                fi

                # Since we know the option was specified in --foo=BAR form, the
                # option was specified erroneously unless the option's long-form
                # spec indicates that it can accept an argument.
                #
                if test ${longopt_spec[${opt}]} -ne 1; then
                    printf "${PROG} (error): option '%s' does not take an argument; bailing out\n" "${opt}" 1>&2
                    f_print_help 1>&2
                    exit 1
                fi

                OPTARG=${OPTARG#*=}  # keep everything after the first '=' sign
                : $PROG \(trace: $LINENO\): OPTARG is: $OPTARG

            else
                : $PROG \(trace: $LINENO\): OPTARG is name-only style

                opt="$OPTARG"
                : $PROG \(trace: $LINENO\): opt is: $opt

                if test -z "${opt}"; then

                    # This should be a "can't happen" scenario; since bash's 'getopts'
                    # implementation should directly handle the magic '--' token, we
                    # should never fall through here.

                    printf "${PROG} (BUG) [line $LINENO]: received empty OPTARG, which means getopts did not handle the stand-alone '--' token; bailing out\n" 1>&2
                    exit 1
                fi

                : $PROG \(trace: $LINENO\): a non-empty long option name must be at least two characters in length
                if test ${#opt} -lt 2; then
                    printf "${PROG} (error): invalid long option '%s'; bailing out\n" "${opt}" 1>&2
                    f_print_help 1>&2
                    exit 1
                fi

                t_exists=false
                for one_key in "${!longopt_spec[@]}"; do
                    if test "${opt}" = "${one_key}"; then
                        t_exists=true
                        break
                    fi
                done

                : $PROG \(trace: $LINENO\): a long option name must be one that the program is expecting
                if $t_exists; then :; else

                    printf "${PROG} (error): invalid long option '%s'; bailing out\n" "${opt}" 1>&2
                    f_print_help 1>&2
                    exit 1
                fi

                # We know the option was specified in one of the following forms:
                #
                #     --foo
                # or:
                #     --foo FOOVAL
                #
                # The option's long-form spec will tell us whether or not an argument is
                # expected for the option.
                #
                if test ${longopt_spec[${opt}]} -eq 1; then

                    # If bumping OPTIND would put us more than one beyond the "last pos
                    # plus one", then there is no argument provided at position OPTIND for
                    # us to consume.
                    #
                    if (( $(( $OPTIND + 1 )) > pos_last_plus_one )); then

                        printf "${PROG} (error): missing argument for option -${OPTARG}\n" 1>&2
                        f_print_help 1>&2
                        exit 1
                    fi

                    OPTARG=${@:${OPTIND}:1}
                    (( ++OPTIND ))
                    : $PROG \(trace: $LINENO\): manually incremented OPTIND to: $OPTIND
                fi
            fi
        fi

        # Normal getopts style processing happens beneath here, with the slight
        # twist that 'opt' may contain a long-form option name.

        case $opt in

            'h' | 'help' )
                # print help message
                f_print_help
                exit 0
                ;;

            'V' | 'version' )
                # print program version info
                f_print_version
                exit 0
                ;;


            'c' | 'clone-if-missing' )
                DO_CLONE_IF_NOT_PRESENT=true
                ;;

            'm' | 'missing-only')
                FETCH_ONLY_MISSING=true
                # The '-m' option implies the '-c' option, so:
                DO_CLONE_IF_NOT_PRESENT=true
                ;;

            'u' | 'upstream-remote-if-missing' )
                DO_CREATE_UPSTREAM_REMOTE_IF_NOT_PRESENT=true
                ;;


            'v' | 'verbose' )
                # Accumulating 'verbose' opt. A single -v opt simply turns
                # BE_VERBOSE on (info level output); two '-v' opts turns on
                # $DEBUGGING (debug level output); three or more '-v' opts turns
                # tracing on. Note that if you intend to turn tracing on, you'll
                # probably want your -v opts to be the first opts on the command
                # line (so they take effect earlier).
                #
                f_maybe_increase_verbosity
                ;;


            ':')  # getopts put : in opt
                  # Note that we need to restore the leading '-' that getopts
                  # has sliced off.
                  printf "${PROG} (error): missing argument for option -${OPTARG}\n" 1>&2
                  f_print_help 1>&2
                  exit 1
                  ;;

            '?')  # getopts put ? in opt
                  # Unrecognized option. Note that we need to restore the
                  # leading '-' that getopts has sliced off.
                  printf "${PROG} (error): unrecognized option '-%s'; bailing out\n" "${OPTARG}" 1>&2
                  f_print_help 1>&2
                  exit 1
                  ;;

            * )   printf "${PROG} (BUG) [line $LINENO]: unhandled option case; opt: '$opt',  OPTARG: '$OPTARG'\n" 1>&2
                  ;;

        esac
    done
fi

# shift off all arguments already handled
let ii=1;  # shell OPTIND index starts at 1
while (( ii < ${OPTIND} )); do
    shift
    (( ++ii ))
    : $PROG \(trace: $LINENO\): ii is now: $ii
done


# GitHub issue #1: If there are any explicitly requested repos that we do not
# process, then we need to let the user know about it.
#
# See: https://github.com/salewski/ads-github-tools/issues/1
declare -a PROCESSED_REPOS=()

declare -a EXPLICITLY_REQUESTED_REPOS=()

# Any remaining arguments are interpreted as the names of repositories that
# the user specifically wants to operate on.
#
# XXX: We do not currently do anything special to account for the same repo
#      being specified more than once; I'm not yet convinced that we
#      should. If the user tells us to operate on repos "foo bar foo", we'll
#      operate on "foo" twice (though the second will effectively be an
#      elaborate NOOP).
#
while test $# -gt 0 ; do

    _one_repo_name=$1; shift

    if $BE_VERBOSE; then
        printf "${PROG} (info): noting user-specified explicit repo name: \"%s\"\n" "${_one_repo_name}" 1>&2
    fi

    EXPLICITLY_REQUESTED_REPOS+=( "${_one_repo_name}" )
done

for ext_tool in "${NEEDED_EXTERNAL_PROGS[@]}"; do

    t_path=$(builtin type -p "${ext_tool}")
    if test $? -ne 0; then
        printf "${PROG} (error): was unable to locate \"%s\" on PATH; bailing out\n" "${ext_tool}" 1>&2
        exit 1
    fi

    if $DEBUGGING; then
        printf "${PROG} (debug): path to external tool \"%s\": %s\n" "${ext_tool}" "${t_path}" 1>&2
    fi
done


# Refuse to run if we do not recognize the URL as something that will be
# encrypted on the wire. This is intended to help prevent accidentally
# transmitting HTTP Basic Auth credentials in cleartext.
#
re_starts_with_https='^https://'
if test -z "${gl_const_github_api_base_url}"; then
    printf "${PROG} (error): GitHub API base URL is not defined; bailing out\n" 1>&2
    exit 1
fi
if [[ "${gl_const_github_api_base_url}" =~ $re_starts_with_https ]]; then :; else
    printf "${PROG} (error): configured GitHub API base URL (\"%s\") does not start with 'https://'; bailing out\n" "${gl_const_github_api_base_url}" 1>&2
    exit 1
fi
#
re_ends_with_slash='.*[/]$'
if [[ "${gl_const_github_api_base_url}" =~ $re_ends_with_slash ]]; then :; else
    if $BE_VERBOSE; then
        printf "${PROG} (info): configured GitHub API base URL (\"%s\") does not end with a slash; appending slash character\n" "${gl_const_github_api_base_url}" 1>&2
    fi
    gl_const_github_api_base_url="${gl_const_github_api_base_url}/"
    declare -r gl_const_github_api_base_url
    if $BE_VERBOSE; then
        printf "${PROG} (info): configured GitHub API base URL (modified) is now: \"%s\"\n" "${gl_const_github_api_base_url}" 1>&2
    fi
fi
if $BE_VERBOSE; then
    printf "${PROG} (info): configured GitHub API base URL: \"%s\"\n" "${gl_const_github_api_base_url}" 1>&2
fi


re_starts_with_accept='Accept:[[:space:]]'
if test -z "${gl_const_http_accept_github_version}"; then
    printf "${PROG} (error): HTTP 'Accept:' header for GitHub API version is not defined; bailing out\n" 1>&2
    exit 1
fi
if [[ "${gl_const_http_accept_github_version}" =~ $re_starts_with_accept ]]; then :; else
    printf "${PROG} (error): configured HTTP 'Accept:' header (\"%s\") for GitHub API version does not start with 'Accept: '; bailing out\n" "${gl_const_http_accept_github_version}" 1>&2
    exit 1
fi
if $BE_VERBOSE; then
    printf "${PROG} (info): configured HTTP 'Accept:' header for GitHub API version: \"%s\"\n" "${gl_const_http_accept_github_version}" 1>&2
fi


# Note that the gl_const_http_accept_github_version value is known to always
# end with a slash character.
#
# per_page: The GitHub v3 API allows for retrieving results in "page sizes" up
# to 100 (in this case, 100 repositories). If a 'per_page' value greater than
# 100 is specified, then the service silently behaves as if 100 were
# specified. Since we need to slurp down all of the data for our purposes
# here, we specify the maximum page size so we have to make the fewest number
# of remote calls while paging through the results.
#
MY_GITHUB_REPOS_URL="${gl_const_github_api_base_url}user/repos?per_page=100"


# Common global options for use in every 'curl' invocation. Specific
# invocations will require additional options, but such usages should not
# modify this array.
#
declare -a MY_CURL_OPTS=()

# This disables output of curl's progress meter /and/ output of error messages...
MY_CURL_OPTS+=( '--silent' )
# ...but this re-enables output of the error messages.
MY_CURL_OPTS+=( '--show-error' )


# Force use of TLS 1.2. Writing in 2016, all previous versions are known to be
# broken and susceptible to known attacks. Note that the '--tlsv1.2' option
# was added in curl 7.34.0
#
# This is absolutely essential since we're using HTTP Basic Auth (see below).
#
MY_CURL_OPTS+=( '--tlsv1.2' )

# Allow ONLY https, for both the initial request and for redirects
MY_CURL_OPTS+=( '--proto')
MY_CURL_OPTS+=( 'https')
MY_CURL_OPTS+=( '--proto-redir')
MY_CURL_OPTS+=( 'https')


# Tell curl to use HTTP Basic Authentication. This is the curl default, but
# we're explicit about what we expect (and want to avoid any surprises from
# weirdo ~/.curlrc files).
#
# See also: RFC 7617 "The 'Basic' HTTP Authentication Scheme" (2015-09)
#
MY_CURL_OPTS+=( '--basic' )


# User's authentication credentials will be obtained from the user's ~/.netrc
# file. See curl(1) and netrc(5)
#
MY_CURL_OPTS+=( '--netrc'  )

MY_CURL_OPTS+=( '--user-agent' )
MY_CURL_OPTS+=( "$PROG"        )


# Even when we're just making HEAD requests, have curl fail
# MY_CURL_OPTS+=( '--fail' )


# Tell the GitHub service that we're trying to speak v3 of the API. Writing in
# 2016, v3 is the default, but some newer version may become the default in
# the future.
#
MY_CURL_OPTS+=( '--header' )
MY_CURL_OPTS+=( "${gl_const_http_accept_github_version}" )


# We'll build up this multi-line value in memory below. Each line will have
# the form:
#
#     repo_name:repo_full_name:default_branch:is_fork
#
# Example of 4 such lines:
#
#     aas:salewski/aas:master:true
#     abcl:salewski/abcl:master:true
#     abstract-tables:salewski/abstract-tables:master:true
#     ac-nrepl:salewski/ac-nrepl:master:true
#
# The 'is_fork' field will always be either 'true' or 'false', and indicates
# whether or not the repo was forked from another GitHub repository. Where the
# value is 'true', callers know they can make a request to the GitHub API's
# /repos/:owner:repo endpoint to request more comprehensive information about
# the repo that would include a 'parent' object. We return the value here
# because it is also useful to know that such a call need not be made if
# you're only interested in the parent data, or just want to know whether or
# not a parent exists.
#
REPO_DATA_LINES=''

# Pagination: 

# HTTP/1.1 200 OK
# ...
# Link: <https://api.github.com/user/repos?per_page=100&page=2>; rel="next", <https://api.github.com/user/repos?per_page=100&page=4>; rel="last"

# Note that we still obtain info on /all/ repos even if the user has specified
# that we operate only on specific repos (in $EXPLICITLY_REQUESTED_REPOS). If
# the user specified only a couple of repos, then we lose here because we
# technically could query the GitHub service for the info on just those
# specific repos to accomplish our work.  If the user explicitly specifies
# more than a few, though, we're back on solid ground because we can typically
# get the info on all available user repos with fewer than 5 GitHub API calls
# (it is unlikely that a typical GitHub user has more than 500 repos). In any
# event, we do not know which page of the results a particular repo will be
# on, so we need to pull full summary data anyway.
#
MY_TOTAL_REPO_PAGES=$(f_get_gh_user_repos_pagination_count_or_die)
t_cur_page=0
t_keep_going=true
while $t_keep_going; do

    let t_cur_page=$t_cur_page+1

    t_gh_url_for_page=${MY_GITHUB_REPOS_URL}'&page='${t_cur_page}

    if $BE_VERBOSE; then
        printf "${PROG} (info): requesting /user/repos page %s of %s\n" "${t_cur_page}" "${MY_TOTAL_REPO_PAGES}" 1>&2
    fi

    # For now we'll just slurp up all of the repo info into memory; we'll
    # revisit this if needed, but <famous-last-words>we're not expecting to
    # have enough repos that it will be a problem</famous-last-words.
    #
    #     $ jq -r '.[] | .name + ":" + .full_name + ":" + .default_branch + ":" + if (.fork) then "true" else "false" end' < all-repos-per_page-105-001.js | head -n 5
    #     aas:salewski/aas:master:true
    #     abcl:salewski/abcl:master:true
    #     abstract-tables:salewski/abstract-tables:master:true
    #     ac-nrepl:salewski/ac-nrepl:master:true
    #     ack2:salewski/ack2:dev:true
    #
    # UPDATE (2016-07-06): [issue #12] Note that we are working only with
    # repos with owner type 'User' (we are ignoring those with owner type
    # 'Organization'). This is to work around the previously unrealized issue
    # that the /user/repos/ data can include repos that that user (as a member
    # of a particular organization) merely has access to, regardless of
    # whether he also has a personal fork of those repos. The authenticated
    # user's personal fork of such a repo, if he has one, is presented
    # separately.
    #
    # XXX: This has the undesirable effect of preventing this program from
    #      working directly on organization-owned repos. The author needs to
    #      further review how those are intended to work, but if this turns
    #      out to be an artificial limitation is interested in having it
    #      fixed. Patches/pull requests welcome!
    #
    # See also: https://github.com/salewski/ads-github-tools/issues/12
    #
    REPO_DATA_LINES=${REPO_DATA_LINES}\
$'\n'\
$( "${CURL_PROG}" "${MY_CURL_OPTS[@]}" \
        --get                \
        "${t_gh_url_for_page}" \
        | "${JQ_PROG}" -r '.[] '\
'| select( .owner.type == "User" ) '\
'| .name + ":" + .full_name + ":" + .default_branch + ":" + if (.fork) then "true" else "false" end' )

    # The newline embedded between our existing and new REPO_DATA_LINES
    # instances is intended to ensure that the concatenation of the two does
    # not join the first line of the new to the last line of the old. It is
    # possible, though, that we may have just introduced a spurious blank
    # line; we'll strip it out if so.
    #
    REPO_DATA_LINES=$(echo "${REPO_DATA_LINES}" | "${SED_PROG}" -e '/^[[:space:]]*$/d' )
    if test $? -ne 0; then
        printf "${PROG} (error): was unable to strip possible empty line out of REPO_DATA_LINES (working page: %s); bailing out\n" \
               "${t_cur_page}" 1>&2
        exit 1
    fi

    if test $t_cur_page -ge $MY_TOTAL_REPO_PAGES; then
        t_keep_going=false
    fi

done


while IFS=':' read -r repo_name repo_full_name default_branch is_fork; do

    : $PROG \(trace: $LINENO\): repo_name:      "$repo_name"
    : $PROG \(trace: $LINENO\): repo_full_name: "$repo_full_name"
    : $PROG \(trace: $LINENO\): default_branch: "$default_branch"
    : $PROG \(trace: $LINENO\): is_fork:        "$is_fork"

    # Sanity checking
    if test -z "${repo_name}"; then
        printf "${PROG} (BUG): 'repo_name' value is empty; bailing out\n" 1>&2
        exit 1
    fi
    if test -z "${repo_full_name}"; then
        printf "${PROG} (BUG): 'repo_full_name' value is empty; bailing out\n" 1>&2
        exit 1
    fi
    if test -z "${default_branch}"; then
        printf "${PROG} (BUG): 'default_branch' value is empty; bailing out\n" 1>&2
        exit 1
    fi
    if test -z "${is_fork}"; then
        printf "${PROG} (BUG): 'is_fork' value is empty; bailing out\n" 1>&2
        exit 1
    fi
    if   test "${is_fork}" = 'true';  then :
    elif test "${is_fork}" = 'false'; then :
    else
        printf "${PROG} (BUG): invalid value detected for 'is_fork' (\"%s\"); should be either 'true' or 'false'; bailing out\n" \
               "${is_fork}" 1>&2
        exit 1
    fi

    if test "${#EXPLICITLY_REQUESTED_REPOS[@]}" -gt 0; then

        t_repo_is_keeper=false

        for expl_repo_name in "${EXPLICITLY_REQUESTED_REPOS[@]}"; do

            if test "${expl_repo_name}" = "${repo_name}"; then
                t_repo_is_keeper=true
                break;
            fi
        done

        if $t_repo_is_keeper; then :; else

            if $DEBUGGING; then
                printf "${PROG} (debug): repo \"%s\" is not one of those explicitly requested for operation; skipping (okay)\n" \
                       "${repo_name}" 1>&2
            fi
            continue
        fi
    fi

    if $FETCH_ONLY_MISSING; then

        if test -d "${repo_name}"; then
            # We'll treat the presence of a subdirectory with the repo name as "not missing"

            if test "${#EXPLICITLY_REQUESTED_REPOS[@]}" -gt 0; then

                # If we are falling through here then it means that the user
                # explicitly requested the repo, but it's working directory is
                # already present. This will ultimately result in the program
                # exiting with an error status because we are not adding the
                # repo name to our $PROCESSED_REPOS array. With that being the
                # case, we'll print the following message as a warning.

                printf "${PROG} (warning): subdirectory exists for repo name \"%s\"; --missing-only specified; skipping\n" \
                       "${repo_name}" 1>&2
            else

                if $BE_VERBOSE; then
                    printf "${PROG} (info): subdirectory exists for repo name \"%s\"; --missing-only specified; skipping (okay)\n" \
                           "${repo_name}" 1>&2
                fi
            fi

            continue
        fi
    fi

    # If there's a subdirectory beneath the current location with the
    # repository name, then it is probably the git working directory for the
    # project. Note that it is possible to have a project cloned into a
    # directory that does not exactly match the project name, but I don't do
    # that with my own repos.
    #
    if test -d "${repo_name}"; then :; else

        if $DO_CLONE_IF_NOT_PRESENT; then

            if $BE_VERBOSE; then
                if $FETCH_ONLY_MISSING; then
                    # The '--missing-only' option implies '--clone-if-missing',
                    # so we show a slightly different log message to help avoid
                    # confusion in case the user did not explicitly provide
                    # '--clone-if-missing' (which would be redundant if '--missing-only'
                    # was provided).
                    #
                    printf "${PROG} (info): no subdirectory exists for repo name \"%s\"; --missing-only specified, so will clone repo from GitHub\n" "${repo_name}" 1>&2
                else
                    printf "${PROG} (info): no subdirectory exists for repo name \"%s\"; --clone-if-missing specified, so will clone repo from GitHub\n" "${repo_name}" 1>&2
                fi
            fi

            declare t_v_opts=()
            if $BE_VERBOSE; then t_v_opts+=( '--verbose' ); fi
            if $DEBUGGING;  then t_v_opts+=( '--verbose' ); fi
            "${GIT_PROG}" hub "${t_v_opts[@]}" clone "${repo_name}"

            if test $? -ne 0; then
                printf "${PROG} (error): was error while attempting to clone repo \"%s\" from GitHub; bailing out\n" "${repo_name}" 1>&2
                exit 1
            fi

            # Sanity check
            if test -d "${repo_name}"; then :; else
                printf "${PROG} (error): just cloned repo \"%s\", but subdir with that name is not present; bailing out\n" "${repo_name}" 1>&2
                exit 1
            fi
        else
            if $DEBUGGING; then
                printf "${PROG} (debug): no subdirectory named after repo \"%s\"; skipping (okay)\n" "${repo_name}" 1>&2
            fi

            continue
        fi
    fi

    if test -d "${repo_name}/.git"; then :; else
        printf "${PROG} (warning): subdirectory named after repo \"%s\" exists, but is not a git working directory; skipping\n" "${repo_name}" 1>&2
        continue
    fi

    # The main purpose of this program is to 'git fetch upstream', but we know
    # that a repo that is not a fork does not have an 'upstream'.
    #
    # XXX: Note that we're doing this check here (rather than at the top of
    # the loop) to allow for the side effect of cloning GitHub repos if there
    # is no working directory present. This behavior should be considered
    # experimental and subject to change in the future. It happens to be
    # convenient for me to do it this way at the moment, but my gut says we
    # might be better off having a separate tool whose job it is to perform
    # just that task.
    #
    # XXX: You may have other remotes defined, or have a non-github repo that
    # has a remote named 'upstream', but this tool will not operate on
    # them. Our purpose here is only to fetch the 'upstream' repo for GitHub
    # repos.
    #
    if $is_fork; then :; else
        if $BE_VERBOSE; then
            printf "${PROG} (info): repo \"%s\" is not a fork of another GitHub repo, so we do not need to check for an \"upstream\" remote; skipping (okay)\n" "${repo_name}" 1>&2
        fi

        # We will treat this as "processed", just with nothing to do. There's
        # no reason to error out when processing explicitly specified repos
        # just because one or more of them are not forks of other GitHub
        # repos.
        #
        PROCESSED_REPOS+=( "${repo_name}" )

        continue
    fi

    unset CDPATH
    (
        set -o pipefail  # not inherited from parent shell

        cd "${repo_name}" || exit 1  # from subshell

        declare -a t_pipestatus_hold

        "${GIT_PROG}" remote | grep -q --max-count=1 '^upstream$'

        t_pipestatus_hold=( ${PIPESTATUS[@]} )

        if test "${#t_pipestatus_hold[@]}" -ne 2; then
            # This is only possible if we've broken something above, which I
            # did do during development, so I'm leaving it in.
            printf "${PROG} (error): was error while attempting to determine if repo \"%s\" has an \"upstream\" remote defined; bailing out\n" "${repo_name}" 1>&2
            exit 1
        fi

        if test "${t_pipestatus_hold[0]}" -eq 0 \
        && test "${t_pipestatus_hold[1]}" -eq 0; then

            if $DEBUGGING; then
                printf "${PROG} (debug): working dir for repo \"%s\" has an \"upstream\" remote defined\n" "${repo_name}" 1>&2
            fi
            # Keep going...

        elif test "${t_pipestatus_hold[0]}" -eq 0 \
          && test "${t_pipestatus_hold[1]}" -eq 1; then

            # No 'upstream' remote is defined for this repo. Either it is the
            # user's own project (not a fork of some other project), or the
            # 'upstream' remote just wasn't set up. It should be the latter
            # case, though, because we checked the 'fork' flag from the repo's
            # GitHub metadata.

            if $BE_VERBOSE; then
                printf "${PROG} (info): did not find an \"upstream\" remote configured for repo \"%s\"\n" "${repo_name}" 1>&2
            fi

            if $DO_CREATE_UPSTREAM_REMOTE_IF_NOT_PRESENT; then

# vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv

                if $BE_VERBOSE; then
                    printf "${PROG} (info): '-u' (--upstream-remote-if-missing) option was specified; will attempt to create \"upstream\" git remote for repo \"%s\"\n" "${repo_name}" 1>&2
                fi

                # We will set up (using the git-hub tool) an "upstream" remote
                # that points to the parent.

# FIXME: go
#     I thought git-hub would just add the 'upstream' repo here, but upon
#     closer reading I see that is not the case. We're just doing this inline
#     for now, but it might be a better fit as an enhancement to 'git-hub'.
                # printf "${PROG} (WIP): '--upstream-remote-if-missing' feature not yet fully implemented; bailing out\n" 1>&2
                # exit 1
# FIXME: end

                # declare t_v_opts2=()
                # if $BE_VERBOSE; then t_v_opts2+=( '--verbose' ); fi
                # if $DEBUGGING;  then t_v_opts2+=( '--verbose' ); fi

                # git hub "${t_v_opts2[@]}" clone "${repo_name}"

                # if test $? -ne 0; then
                #     printf "${PROG} (error): was error while attempting to establish the \"upstream\" remote for repo \"%s\" from via 'git hub clone...'; bailing out\n" "${repo_name}" 1>&2
                #     exit 1
                # fi


                # We'll ask the GitHub service if this repo has a "parent",
                # which it should (read as: "will, modulo changes due to
                # timing since we checked") because we've already checked
                # above. If not (won't happen), then there's nothing left to
                # do. Note that we have to make a call to the service
                # inquiring about a specific repo to obtain the parent's
                # 'clone_url'; it is not available in the output of the full
                # list of repos which we've already obtained. This could be a
                # bit expensive against your rate limit if you have a large
                # number of repos, but if most of those repos are forks it
                # will only be expensive the first time the program is run to
                # update those repos.

                # From the GitHub v3 API:
                #
                #     Get
                #
                #     GET /repos/:owner/:repo
                #     Response
                #
                #     The parent and source objects are present when the
                #     repository is a fork. parent is the repository this
                #     repository was forked from, source is the ultimate source
                #     for the network.

                # Note that the repo_full_name value here has the form
                # 'username/repo_name', so matches the structure of the URL
                # needed.
                #
                t_gh_url_for_this_repo="${gl_const_github_api_base_url}repos/${repo_full_name}"

                if $BE_VERBOSE; then
                    printf "${PROG} (info): querying GitHub service to obtain parent clone url for repo \"%s\"\n" "${repo_name}" 1>&2
                fi

                t_parent_clone_url=$( "${CURL_PROG}" "${MY_CURL_OPTS[@]}" \
                                      --get                \
                                      "${t_gh_url_for_this_repo}" \
                                      | "${JQ_PROG}" -r '.clone_url' )
                if test $? -ne 0; then
                    printf "${PROG} (error): was unable to query GitHub service to obtain clone url for repo \"%s\"; bailing out\n" "${repo_name}" 1>&2
                    exit 1  # from subshell
                fi
                if test -z "${t_parent_clone_url}"; then
                    printf "${PROG} (error): was unable to obtain clone url for repo \"%s\"; bailing out\n" "${repo_name}" 1>&2
                    exit 1  # from subshell
                fi

                if $BE_VERBOSE; then
                    printf "${PROG} (info): setting up \"upstream\" remote for repo \"%s\" to: %s\n" "${repo_name}" "${t_parent_clone_url}" 1>&2
                fi

                "${GIT_PROG}" remote add upstream "${t_parent_clone_url}"

                if test $? -ne 0; then
                    printf "${PROG} (error): was unable to establish \"upstream\" remote for repo \"%s\"; bailing out\n" "${repo_name}" 1>&2
                    exit 1
                fi

                if $DEBUGGING; then
                    printf "${PROG} (info): successfully set up \"upstream\" remote for repo \"%s\" to: %s\n" "${repo_name}" "${t_parent_clone_url}" 1>&2
                fi

# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            else
                printf "${PROG} (warning): no remote named \"upstream\" defined for repo \"%s\"; skipping (okay)\n" "${repo_name}" 1>&2
                exit 0  # from subshell
            fi

        else

# FIXME: Introduce a "keep going" feature to avoid bailing out here
# FIXME: Introduce a "skip repo" feature to allow caller to exclude processing of some repo subidrs

            printf "${PROG} (error): was error while attempting to determine if repo \"%s\" has an \"upstream\" remote defined; bailing out\n" "${repo_name}" 1>&2
            exit 1
        fi

        if $BE_VERBOSE; then
            printf "${PROG} (info): invoking 'git fetch upstream' for repo \"%s\"\n" "${repo_name}" 1>&2
        fi

        "${GIT_PROG}" fetch upstream
        if test $? -ne 0; then
            printf "${PROG} (error): was error while attempting to 'git fetch upstream' for repo \"%s\"; bailing out\n" "${repo_name}" 1>&2
            exit 1
        fi

        if $DEBUGGING; then
            printf "${PROG} (debug): successfully invoked 'git fetch upstream' for repo \"%s\"\n" "${repo_name}" 1>&2
        fi
    )

    if test $? -ne 0; then
# FIXME: see above note about introducing a "keep going" feature

        # We're expecting that an error message would have already been printed by the subshell
        exit $?
    fi

    PROCESSED_REPOS+=( "${repo_name}" )

done < <(echo "$REPO_DATA_LINES")


if test ${#EXPLICITLY_REQUESTED_REPOS[@]} -gt 0; then

    # We use this to "remember" the names of all repo names that have not been
    # processed. This allows us to present the complete list to the user in
    # our error message.
    #
    # Using an assoc. array to automatically dedup the list of names. Each key
    # is the name of a repo that should appear in the error message.
    #
    # See also: https://github.com/salewski/ads-github-tools/issues/23
    #
    declare -A t_unprocessed_repo_names_to_counts=()

    for t_requested_repo_name in "${EXPLICITLY_REQUESTED_REPOS[@]}"; do

        t_processed_it=false

        for t_processed_repo_name in "${PROCESSED_REPOS[@]}"; do
            if test "${t_requested_repo_name}" = "${t_processed_repo_name}"; then
                t_processed_it=true
                break
            fi
        done

        if $t_processed_it; then :; else
            (( ++t_unprocessed_repo_names_to_counts["${t_requested_repo_name}"] ))
            : $PROG \(trace: $LINENO\): name of unprocessed repo name \""${t_requested_repo_name}"\" seen ${t_unprocessed_repo_names_to_counts["${t_requested_repo_name}"]} time\(s\)
        fi
    done

    if test "${#t_unprocessed_repo_names_to_counts[@]}" -gt 0; then
        t_maybe_ess='s'
        if test "${#t_unprocessed_repo_names_to_counts[@]}" -eq 1; then
            t_maybe_ess=''
        fi

        # Need single value for our printf '%s' conversion specification
        # below.
        #
        # Feeding the names of all unprocessed repo names (one per line) to
        # 'xargs echo' has the effect of flattening the list down to a single
        # line (well, a single line for each 'echo' invocation; in the common
        # case all will fit on a single command line an result in the pretty
        # output that we intend, but this will work either way because we
        # capture the output as a single value -- if multiple lines are
        # produced the output will just be a bit uglier).
        #
        # Note that (non-built-in) 'echo' is the default "utility" invoked by
        # xargs since at least as far back as SUSv2 (1998), but we specify it
        # explicitly for clarity.
        #
        t_unprocessed_repo_names_as_string="$( printf '%s\n' "${!t_unprocessed_repo_names_to_counts[@]}" | "${XARGS_PROG}" "${ECHO_PROG}" )"
        if test $? -ne 0; then
            printf "${PROG} (error): was unable to flatten list of %d unprocessed repo names; bailing out\n" \
                   "${#t_unprocessed_repo_names_to_counts[@]}" 1>&2
            exit 1
        fi

        printf "${PROG} (error): did not process explicitly requested repo%s: %s; bailing out\n" \
               "${t_maybe_ess}" \
               "${t_unprocessed_repo_names_as_string}" 1>&2
        exit 1
    fi
fi

if $BE_VERBOSE; then
    printf "${PROG} (info): completed successfully\n" 1>&2
fi

exit 0;


#
# ----------------------------------------------------------------------------
# Documentation
#
# The docs are in Perl's POD format, so you can run either the 'perldoc' or
# 'pod2man' programs on this file to produce a man page.
#
# To generate a man page for distribution (in a tarball or RPM, for instance),
# you'll probably want to run pod2man something like this:
#
#     $ pod2man /path/to/this/file \
#               --center='ads-github-tools' \
#               --release='ads-github-tools-0.1.0' \
#               --section='1' \
#               > /outputdir/ads-github-fetch-all-upstreams.1
#
# To inspect the page formatting, etc., you can pipe the above 'pod2man'
# command to:
#
#     'man -l -'
#
# instead of redirecting the output to a file.
#
# ----------------------------------------------------------------------------

=pod

=head1 NAME

  ads-github-fetch-all-upstreams - Fetch all of user's GitHub repos, if needed


=head1 SYNOPSIS

  ads-github-fetch-all-upstreams --help
  ads-github-fetch-all-upstreams --version

  ads-github-fetch-all-upstreams [OPTION...] [REPO...]


=head1 DESCRIPTION

The C<ads-github-fetch-all-upstreams> program is part of the
C<ads-github-tools> project.

The C<ads-github-fetch-all-upstreams> program invokes C<git fetch upstream>
for all of the user's GitHub repos that are present (in repository working
directories beneath the current location). With appropriate options, will
clone some or all missing repos and set up the 'upstream' remote.

FIXME: docs still a wip


=head1 OPTIONS

Below are the command line options currently accepted by
C<ads-github-fetch-all-upstreams>.


=over 4

=item -h, --help

Print help usage message


=item -V, --version

Print the version of the program to stdout and then exit.


=item -c, --clone-if-missing

Use L<git-hub(1)> to clone your missing repos from GitHub.


=item -m, --missing-only

Fetch only repos that are missing locally.

The default behavior of the program is to operate only on working directories
that are present, or only on those repos that are explicitly named on the
command line (two different flavors of "operate only on these" semantics).

Sometimes you want exactly the opposite behavior, though ("fetch all the new
stuff" semantics). Our C<--missing-only> command line option allows the user
to request that behavior.

This option implies C<--clone-if-missing>) (C<-c>), and effectively provides a
shorthand way of invoking:

    $ ads-github-fetch-all-upstreams -c <MISSING_REPO>...

without having to explicitly name (or even know) the values for each missing
repository name.

This behavior is useful, for example, if you have forked a number of different
GitHub repos and want to have them cloned locally without having to wait for
the status of all existing repositories to be checked (which can be a long
time if you have a large number of GitHub repos), and without having to
explicitly name the missing repos on the command line.


=item -u, --upstream-remote-if-missing

Setup 'upstream' remote in existing repo working dirs, if missing


=item -v, --verbose

Turn on verbose mode. Causes program to emit messages on C<stderr> indicating
what it is doing. The option may be specified multiple times to increase
further the level of verbosity. One C<-v> option enables info-level output;
two such opts enable debug-level output; three or more enable trace-level
output.


=item --

Signals the end of options and disables further options processing. This is
useful in the pathological scenario in which a REPO parameter would otherwise
be interpreted as a command line option.

=back


=head1 DIAGNOSTICS

Exits with zero on success, non-zero on error.


=head1 BUGS

=over 4

=item Results from calls to the GitHub API are not currently cached

At the time of writing (2016-05) the author is still working on the
'ads-github-tools' cache implementation, so any information needed from the
upstream GitHub service is requested directly. This may incur unnecessary hits
against the user's GitHub API rate limit. Don't worry, in the typical case we
are only talking about a handful of requests even if the user has a very large
number of repositories (i.e., several hundred).

=item Probably others

If you find any, please report them as described in the C<BUGS> file.

=back


=head1 SEE ALSO

=over 4

=item ads-github-tools(7)

=item ads-github-merge-all-upstreams(1)

=back


=head1 AUTHOR

=over 4

=item Alan D. Salewski  <salewski@att.net>

=back


=head1 COPYRIGHT

Copyright 2016, 2017 Alan D. Salewski

=cut

