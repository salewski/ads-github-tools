#!/bin/bash -

# Copyright (c) 2016 Alan D. Salewski <salewski@att.net>
#
#     This program is free software; you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation; either version 2 of the License, or
#     (at your option) any later version.
#
#     This program is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program; if not, write to the Free Software Foundation,
#     Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301,, USA.

# ads-github-fetch-all-upstreams: Make an authenticated call to the GitHub API
# (using curl) to obtain a list of all of my repositories. For each, if a
# local directory (beneath the current location) is found that matches the
# repo name (and that directory is a git working directory, and it has a
# remote named 'upstream' defined), then this program will change into the
# local working directory for that repo and run a 'git fetch upstream'
# command.
#
# All requests are made over HTTPS.
#
# Authentication
# ==============
# No authentication data is used directly; the curl(1) '-n' (--netrc) option
# is used, so the user is expected to have his GitHub credentials stored in a
# ~/.netrc file. For details on setting that up, see curl(1) and
# netrc(5). Note that curl will not use the ~/.netrc file if the permissions
# allow reading by group or other.
#
# HINT: The relevant line ~/.netrc file content should have the form:
#
#     machine api.github.com login YOUR_USER_NAME password YOUR_GITHUB_PASSWORD
#
# CAVEAT: Use of the netrc(5) configuration means that this tool is ultimately
# using username/password with the GitHub API. Though all communication is
# conducted over HTTPS (so is encrypted "on the wire"), this authentication
# mechanism allows this tool to access the full power of the GitHub API.
#
# DO NOT USE THIS TOOL UNLESS YOU TRUST THAT IT IS NOT ABUSING THIS TRUST.
#
# Use of the OAuth mechanisms would allow for the access needed by this
# program while preventing use of the access it does not need. I'm not
# worrying about that at the moment though, as I'm the only user, and I expect
# that anything more elaborate should probably be integrated into a more
# featureful tool (such as 'git-hub', which already has OAuth support).
#
# Motivation
# ==========
# With even a relatively small number of GitHub repositories, keeping local
# trees up to date with upstreams can be a chore. This tool performs one piece
# of automation that can contribute to a solution.
#
# TODO
# ====
#
#     * Provide an option to have non-existing working directories created by
#       cloning my fork repo in GitHub and then setting up the 'upstream'
#       remote to the parent of the fork (the repository from which I created
#       the fork originally). The 'git-hub clone' command does this as it's
#       default behavior.
#
# See Also:
# =========
#
#     * The 'Repos' section of the GitHub API (v3)
#       https://developer.github.com/v3/repos/
#
#     * The 'git-hub' tool:
#       https://github.com/sociomantic-tsunami/git-hub

declare -r PROG='ads-github-fetch-all-upstreams'

set -o pipefail


# FIXME: one day this will be filtered in at build time
declare -r MAINTAINER='Alan D. Salewski <salewski@att.net>'

# FIXME: one day this will be filtered in at build time
declare -r VERSION='0.0.1'

# FIXME: one day this will be filtered in at build time
# This variable is replaced at build time
# declare -r gl_const_build_date='@BUILD_DATE@'
# declare -r gl_const_release="${VERSION}  (built: ${gl_const_build_date})"
declare -r gl_const_release="${VERSION}"

BE_VERBOSE=false # info-level output; override with one '-v' opt

# This one implies BE_VERBOSE, too
DEBUGGING=false  # debug-level output; override with two '-v' opts


# If specified, the '--clone-if-missing' command line option directs this
# program to clone any repository from GitHub where the local git working
# directory is missing. The default behavior (when that option is not
# specified) is to just operate on the working directories that are present.
#
# Note that we invoke the 'git-hub' tool (via 'git hub clone') to implement
# this feature. That means that we'll not only clone the repository if it is
# missing, but we'll also have the 'upstream' remote set up (if the repo is a
# fork of another repo). This works regardless of whether or not the working
# directory was present when this command was invoked.
#
DO_CLONE_IF_NOT_PRESENT=false


# It may be the case that we have cloned one of our repositories manually, but
# for whatever reason have not set up the 'upstream' remote to point to the
# parent GitHub repository from which ours was cloned.
#
# By default, this program will not perform any action on any such working
# directories. But if the '-u' ('--upstream-remote-if-missing') option is
# specified, we will take action to setup a git remote named "upstream" using
# the parent repo's clone url.
#
DO_CREATE_UPSTREAM_REMOTE_IF_NOT_PRESENT=false


# Folks using GitHub Enterprise might access their API at a different
# location, so we parameterize the base URL for the GitHub API. MAKE SURE THIS
# URL INDICATES HTTPS (not just HTTP -- you do not want your HTTP Basic Auth
# credentials being transmitted in cleartext!).
#
# This is NOT declared read-only here because there is some minor fixup that
# we attempt so users do not need to be concerned with whether or not the URL
# ends with a slash. For our purposes we need the value to end with a slash,
# and will add a slash to the end if it is not specified here.
#
declare    gl_const_github_api_base_url='https://api.github.com/'

# We'll help future-proof this program by explicitly requesting version 3 of
# the GitHub API (although it is the default at the time of writing
# (2016-04)).
#
declare -r gl_const_http_accept_github_version='Accept: application/vnd.github.v3+json'

# jq - command line JSON parser and manipulation language
#      see: https://github.com/stedolan/jq
#
# git-hub - command line GitHub API tool; works as 'git' subcommand if found
#           on PATH
#           see: https://github.com/sociomantic-tsunami/git-hub
#                https://www.kernel.org/pub/software/scm/git/docs/howto/new-command.html
#
declare -a NEEDED_EXTERNAL_PROGS=(
    cat
    curl
    expr
    head
    jq
    git
    git-hub
    sed
    tr
)


declare -a F_CLEANUP_HOOK_NAMES=()

function f_add_cleanup_hook_name () {
    F_CLEANUP_HOOK_NAMES+=( $1 );
}


function f_cleanup () {

    if test ${#F_CLEANUP_HOOK_NAMES[@]} -eq 0; then
        # No cleanup hooks, so nothing to do
        return
    fi

    local cleanup_hook
    local idx

    let idx=${#F_CLEANUP_HOOK_NAMES[@]}-1

    # Note that we're running the cleanup hooks in opposite order from which
    # they were installed.
    #
    while test $idx -ge 0; do

        cleanup_hook=${F_CLEANUP_HOOK_NAMES[$idx]}

        if $BE_VERBOSE; then
            printf "${PROG} (info): running cleanup hook: [%s]\n" "${cleanup_hook}" 1>&2
        fi

        test -n "$cleanup_hook" && eval "$cleanup_hook"

        let idx=$idx-1
    done
}

function f_cleanup_and_die () {
    f_cleanup
    exit 1
}

trap 'printf "$PROG (warn): HUP signal caught; bailing out\n"  1>&2; f_cleanup_and_die' HUP
trap 'printf "$PROG (warn): INT signal caught; bailing out\n"  1>&2; f_cleanup_and_die' INT
trap 'printf "$PROG (warn): QUIT signal caught; bailing out\n" 1>&2; f_cleanup_and_die' QUIT
trap 'printf "$PROG (warn): TERM signal caught; bailing out\n" 1>&2; f_cleanup_and_die' TERM

trap 'f_cleanup' EXIT



f_print_help () {

    cat <<EOF
usage: $PROG [OPTION...] [REPO...]
Invokes 'git fetch upstream' for all of the user's GitHub repos that are
present. With appropriate options, will clone some or all missing repos and
set up the 'upstream' remote.

Mandatory arguments to long options are mandatory for short options too.

  -h, --help                        Print this help message on stdout
  -V, --version                     Print the version of the program on stdout
  -c, --clone-if-missing            Use git-hub(1) to clone your missing repos from GitHub
  -u, --upstream-remote-if-missing  Setup 'upstream' remote in existing repo working dirs, if missing

  -v, --verbose                     Print program progress messages on stderr. Specify multiple
                                      times to increase verbosity: info, debug, and tracing (set -x)

      --                            Signals the end of options and disables further options processing.

Report bugs to $MAINTAINER.
EOF
}

f_print_version () {
    cat <<EOF
${PROG} ${gl_const_release}
Copyright (C) 2016 Alan D. Salewski
License GPLv2+: GNU GPL version 2 or later <http://gnu.org/licenses/gpl.html>.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Written by Alan D. Salewski.
EOF
}

# Indicates whether or not the provided MAYBE_ARRAY_NAME parameter is the name
# of a bash array.
#
f_is_array () {

    local __required_count=1
    if test $# -ne ${__required_count}; then
        printf "${PROG} (BUG): ${FUNCNAME}() invoked with %d args; exactly %d required; bailing out\n" \
            $# ${__required_count} 1>&2
        exit 1
    fi

    local -r __maybe_array_name=$1

    local -r __has_opt_a='declare -[A-Zb-z]*a'
    if [[ "$(declare -p "${__maybe_array_name}" 2>/dev/null)" =~ ${__has_opt_a} ]]; then
        return 0
    fi

    return 1
}

# Works similarly to bash's built-in 'shift' command, but operates on the
# named array rather than $@.
#
# Usage: f_shift ARRAY_NAME [n]
#
# If N is not given, it is assumed to be 1.
#
# Returns success unless N is negative or greater than the number of elements
# in the named array.
#
f_shift () {

    local __required_min_count=1
    local __max_allowed_count=2
    if test $# -lt ${__required_min_count}; then
        printf "${PROG} (BUG): ${FUNCNAME}() invoked with %d args; at least %d required; bailing out\n" \
               $# ${__required_min_count} 1>&2
        exit 1
    fi
    if test $# -gt ${__max_allowed_count}; then
        printf "${PROG} (BUG): ${FUNCNAME}() invoked with %d args; at most %d allowed; bailing out\n" \
               $# ${__max_allowed_count} 1>&2
        exit 1
    fi

    local -r __array_name=$1

    local __shift_count=1  # default
    if test $# -eq 2; then
        __shift_count=$2
    fi
    local -r __shift_count

    local -r __t_re_positive_integer='^[[:digit:]]{1,}$'

    if [[ "${__shift_count}" =~ ${__t_re_positive_integer} ]]; then :; else
        printf "${PROG} (error): ${FUNCNAME}() N (shift count) parameter must be a positive integer; got \"%s\"\n" "${__shift_count}" 1>&2
        return 1
    fi

    if f_is_array "${__array_name}"; then :; else
        printf "${PROG} (error): ${FUNCNAME}() value of ARRAY_NAME parameter (\"%s\") does not name an array\n" "${__array_name}" 1>&2
        return 1
    fi

    # XXX: This is a hack to work around the bash syntax collision in which
    #      ${!foo[@]} expands to the index positions of the elements in the
    #      array rather than an indirect reference (which works for non-array
    #      types such as ${!foo}). By putting the '[@]' subscript into the
    #      value of the named array, we /can/ iterate over it's values below
    #      using the indirect reference syntax.
    #
    local __t_arrayref="${__array_name}[@]"

    # for tval in "${!__t_arrayref}"; do  # iterating over elements of indirectly referenced array
    #     : $PROG \(trace: $LINENO\): [before]: one t_the_array value: $tval
    # done

    # This loses when command array values contain shell syntax (e.g.,
    # '--blah$BLAH'), so we do it the long way down below:
    #
    # eval "${__array_name}=( ${!__t_arrayref:${__shift_count}} )"

    declare -a __t_new_array=()
    local __t_cnt=0
    for tval in "${!__t_arrayref}"; do  # iterating over elements of indirectly referenced array
        (( ++__t_cnt ))

        if (( ${__t_cnt} <= ${__shift_count} )); then
            : $PROG \(trace: $LINENO\): shifting off element ${__t_cnt} from array ${__array_name} : val: $tval
            continue
        fi

        __t_new_array[$(( ${__t_cnt} - 1 ))]="$tval"
    done

    for tval in "${__t_new_array[@]}"; do
        : $PROG \(trace: $LINENO\): [after]: one t_new_array value: $tval
    done

    eval "${__array_name}=()"  # empty out
    for t_idx in "${!__t_new_array[@]}"; do
        eval "${__array_name}[${t_idx}]=\"$(printf '%q' "${__t_new_array[${t_idx}]}")\""
    done

# # DEBUG go
#     # This just allows for inspection of the referenced array as it will
#     # appear to the caller once this function returns.
#     #
#     local __t_arrayref2="${__array_name}[@]"

#     for tval in "${!__t_arrayref2}"; do  # iterating over elements of indirectly referenced array
#         : $PROG \(trace: $LINENO\): [final]: one ${__array_name} value: $tval
#     done
# # DEBUG end

    return 0  # success
}

# Invoked by our accumulating '-v' (--verbose) option. Increases the program
# output verbosity level by "one stage".
#
# If we have not yet increased the verbosity, then enables info-level output
# ($BE_VERBOSE).
#
# If we are currently at info-level verbosity, then enables debug-level output
# ($DEBUGGING).
#
# If we are currently at debug-level verbosity, then enables trace-level
# output (set -x).
#
# If we are already at trace-level verbosity, then this function has no effect
# (is effectively a NOOP).
#
f_maybe_increase_verbosity () {

    if $BE_VERBOSE; then

        # We are (at least) at info-level verbosity currently.
        if $DEBUGGING; then
            # We are (at least) at debug-level verbosity currently.

            case $- in
                *x* )
                    : $PROG \(trace: $LINENO\): tracing already enabled
                    ;;
                * )
                    printf "${PROG} (debug): additional verbosity requested; enabling trace-level output\n" 1>&2
                    set -x
                    ;;
            esac
        else
            printf "${PROG} (info): additional verbosity requested; enabling debug-level output\n" 1>&2
            DEBUGGING=true
        fi
    else
        printf "${PROG} (info): verbose output requested; enabling info-level output\n" 1>&2
        BE_VERBOSE=true
    fi
}

# Intended to be invoked prior to "the real" command line options processing
# being done. Modifies the provided OUTPUT_ARRAY_NAME array variable (after
# emptying it out) to contain elements that are the positional parameters of a
# rewritten representation of the command line; any /legitimate/ short-form
# options are expanded to use their long-form option representations.
#
# This also allows us to leverage the built-in getopts's ability to parse
# "bundled" short-form options, both with and without option arguments.
#
# The idea is to allow all of the following to work (while not precluding the
# use of long-form command line options), which is difficult to implement in a
# general fashion without getopts's help (or by using the external 'getopt'
# tool, which is both an external dependency we would rather avoid, and is
# infamously non-portable):
#
#     $ progname -v -f fooval
#     $ progname -v -ffooval
#     $ progname -vffooval
#     $ progname -ffooval -v
#
#
# #NAME: Summary of options preprocessing behavior
# |-------------------------------+-------------+----------+------------------------------------------------------------------------------------------|
# | Opt Form Style                | Recognized? | Bundled? | Outcome                                                                                  |
# |-------------------------------+-------------+----------+------------------------------------------------------------------------------------------|
# | short-form                    | Y           | Y        | rewritten in long-form                                                                   |
# | short-form                    | Y           | N        | rewritten in long-form                                                                   |
# |-------------------------------+-------------+----------+------------------------------------------------------------------------------------------|
# | short-form                    | N           | Y        | rewritten as unbundled short-form                                                        |
# | short-form                    | N           | N        | passed through "as is"                                                                   |
# |-------------------------------+-------------+----------+------------------------------------------------------------------------------------------|
# | long-form                     | n/a         | n/a      | all are passed through "as is"                                                           |
# |-------------------------------+-------------+----------+------------------------------------------------------------------------------------------|
# | non-option arguments          | n/a         | n/a      | all are passed through "as is" (but see next item)                                       |
# |-------------------------------+-------------+----------+------------------------------------------------------------------------------------------|
# | end-of-options indicator (--) | n/a         | n/a      | (effectively) passed through "as is", though we jump through flaming hoops for the cause |
# |-------------------------------+-------------+----------+------------------------------------------------------------------------------------------|
#
#
# CAREFUL: Since we special-case verbosity output handling here (to allow it
#          to occur as early as possible) it is important that this function
#          be invoked within the same bash process as its caller (as opposed
#          to being invoked in a subshell). A subprocess would be unable to
#          directly affect the state of the parent process, so the parent
#          process would not know whether or not the verbosity levels had been
#          increased (...at least not without implementing a more complicated
#          protocol).
#
# Usage (XXX: subject to change):
#
#     declare -a MY_COMMAND_LINE_OPTIONS=( "$@" )
#     declare -a MY_COMMAND_LINE_OPTIONS_REWRITTEN=()
#     f_rewrite_command_line_or_die MY_COMMAND_LINE_OPTIONS_REWRITTEN
#     set -- "${MY_COMMAND_LINE_OPTIONS_REWRITTEN[@]}"
#     <<"Real" command line options processing here>>
#
# XXX: Use of the array named MY_COMMAND_LINE_OPTIONS is currently hard-coded.
#
# FIXME: Generalize this to work with a provided data map (similar in spirit
#        to getopts's OPTSTRING parameter). A similar idea expressed here
#        would need to provide (at least) both the long- and short-form option
#        names and an indicator as to whether or not they take an argument.
#
f_rewrite_command_line_or_die () {

    local __required_min_count=1
    local __max_allowed_count=1
    if test $# -lt ${__required_min_count}; then
        printf "${PROG} (BUG): ${FUNCNAME}() invoked with %d args; at least %d required; bailing out\n" \
               $# ${__required_min_count} 1>&2
        exit 1
    fi
    if test $# -gt ${__max_allowed_count}; then
        printf "${PROG} (BUG): ${FUNCNAME}() invoked with %d args; at most %d allowed; bailing out\n" \
               $# ${__max_allowed_count} 1>&2
        exit 1
    fi

    local -r __output_array_name=$1

    if f_is_array "${__output_array_name}"; then :; else
        printf "${PROG} (error): ${FUNCNAME}() value of OUTPUT_ARRAY_NAME parameter (\"%s\") does not name an array\n" "${__output_array_name}" 1>&2
        return 1
    fi


    # We'll rewrite the command line below to expand (possibly grouped)
    # short-form options (some of which may have option arguments) into their
    # respective long-form representations. We'll be using bash's builtin
    # 'getopts' command for that purpose, which honors the value '--' to mean
    # "end of options". However, getopts does not provide a mechanism to allow
    # us to determine if it stopped processing options due to the presence of
    # that value, and /not/ providing it on our rewritten command line, if
    # needed, could actually cause an invalid invocation. We therefore make a
    # note of the index positions at which the value occurs, and use this info
    # later to determine whether or not we need to add the value back into our
    # rewritten command line.
    #
    # Note that we need to deal with pathological situations here, as getopts
    # will (legitimately) parse '--' as an option argument value rather than
    # as "end of options" if it appears in a location where an option is
    # expecting an argument.
    #
    # If getopts has stopped parsing due to the presence of a '--' value, then
    # we can detect that scenario by counting the the number of '--' values
    # still available in the combined options values and the remaining
    # unparsed portion of the command line. If getopts stopped processing due
    # to '--', the count will be off by one.
    #
    # Note that we record the position numbers mainly for debugging purposes;
    # what we are really interested in are the counts of the items in each
    # of the __t_end_of_options_* arrays.
    #
    local -a __t_end_of_options_positions=()
    local __t_pos=0
    for __t_posval in "${MY_COMMAND_LINE_OPTIONS[@]}"; do
        (( ++__t_pos ))
        if test "${__t_posval}" = '--'; then
            __t_end_of_options_positions+=( $__t_pos )
        fi
    done

    local -a __t_end_of_options_seen_as_optargs=()
    local -a __t_end_of_options_seen_unprocessed=()

    local -a __t_expanded_command_line=()
    if test ${#MY_COMMAND_LINE_OPTIONS[@]} -gt 0; then
        # Re-write the command line to expand (perhaps grouped) short-form
        # options into their respective long-form variants.

        # Any arguments not recognized based on the specification provided
        # here are simply ignored by 'getopts' operating in "silent mode".

        # This allows us to stop looking at a positional token once we've
        # consumed it. When getopts sees a long-form option, it attempts to
        # parse each character of it as short form options. While it is doing
        # this, OPTIND does not increase, so we use that fact to detect the
        # scenario.
        local __t_skip_until=-1

        while builtin getopts ':chuVv' __t_opt "${MY_COMMAND_LINE_OPTIONS[@]}"; do

            : $PROG \(trace: $LINENO\): OPTIND: $OPTIND, __t_opt: ${__t_opt}, OPTARG: $OPTARG

            if (( $OPTIND < $__t_skip_until )); then
                : $PROG \(trace: $LINENO\): OPTIND is $OPTIND \(less than __t_skip_until: ${__t_skip_until}\) : skipping
                continue
            fi

            case ${__t_opt} in
                'c' ) __t_expanded_command_line+=( '--clone-if-missing' ) ;;
                'h' ) __t_expanded_command_line+=( '--help' ) ;;
                'u' ) __t_expanded_command_line+=( '--upstream-remote-if-missing' ) ;;
                'V' ) __t_expanded_command_line+=( '--version' ) ;;

                'v' )
                    # As a special case, we will process our accumulating '-v'
                    # options in this section directly (as opposed to simply
                    # adding them to our rewritten command line). For
                    # debugging purposes, we want to be able to increase the
                    # verbosity as early as possible.
                    #
                    # A single -v opt simply turns BE_VERBOSE on (info level
                    # output); two '-v' opts turns on $DEBUGGING (debug level
                    # output); three or more '-v' opts turns tracing on.
                    #
                    # Note that if you intend to turn tracing on, you'll
                    # probably want your -v opts to be the first opts on the
                    # command line (so they take effect earlier).
                    #
                    f_maybe_increase_verbosity
                    ;;

                ':')  # getopts put : in ${__t_opt}
                    printf "${PROG} (ERROR): missing argument for option -${OPTARG}\n" 1>&2
                    f_print_help 1>&2
                    exit 1
                    ;;

                '?')  # getopts put ? in ${__t_opt}

                    # If an "invalid" option is seen, 'getopts' places the
                    # option character found into OPTARG. So a short- or
                    # long-form option was encountered that is not recognized
                    # by our deliberately limited optstring above.
                    #
                    # We will simply restore the '-' character that 'getopts'
                    # has stripped off, and add the option to our rewritten
                    # command line (so a '-Z' option is seen below as '-z'
                    # rather than just 'z', and a '--foo' option is see as
                    # '--foo' rather than '-foo')
                    #
                    # Note that this could leave invalid short-form options on
                    # the command line, but they will be "standalone" (not
                    # "bundled"); the caller will handle that scenario
                    # downstream from this function invocation.
                    #
                    : $PROG \(trace: $LINENO\): preliminarily unrecognized opt: -$OPTARG
                    if test "${OPTARG}" = '-'; then

                        # getopts has started parsing a long-form command line
                        # option. It sliced off the first '-', and has
                        # interpretted the second as the name of the option.
                        #
                        # Recall that OPTIND contains the index of the /next/
                        # argument to be processed, so we need to subtract one
                        # to get the index of the argument that it getopts is
                        # /currently/ parsing.
                        #
                        # We'll take the entire positional value to pass
                        # through...
                        #
                        __t_expanded_command_line[${#__t_expanded_command_line[@]}]=${MY_COMMAND_LINE_OPTIONS[$(( $OPTIND - 1))]}
                        #
                        # ...and ignore output from getopts until it moves on
                        # to parsing the next positional element (if any):
                        #
                        __t_skip_until=$(( $OPTIND + 1 ))
                    else
                        # Just a run-of-the-mill short-form option parse for
                        # an unrecognized opt. Restore the hyphen character
                        # before the option character before adding it to our
                        # collection.
                        #
                        __t_expanded_command_line+=( '-'"$OPTARG" )
                    fi
                    ;;

                * ) # Anything we would want to avoid consuming, but since
                    # getopts stops processing upon encountering non-option
                    # command line arguments, we should never fall through
                    # here.
                    #
                    printf "$PROG (BUG): unaccounted for command line options processing; option is \"%s\", OPTARG is \"%s\", OPTIND is \"%s\"; bailing out\n" \
                           "${__t_opt}" "${OPTARG}" "${OPTIND}" 1>&2
                    exit 1
                    ;;
            esac

            : $PROG \(trace: $LINENO\): __t_expanded_command_line element count: ${#__t_expanded_command_line[@]}
            for traceidx in ${!__t_expanded_command_line[@]}; do
                : $PROG \(trace: $LINENO\): __t_expanded_command_line[${traceidx}]:  ${__t_expanded_command_line[${traceidx}]}
            done
        done
    fi

    # shift off all options and arguments already handled
    local __t_ii
    let __t_ii=1
    while (( __t_ii < ${OPTIND} )); do
        f_shift 'MY_COMMAND_LINE_OPTIONS'
        (( ++__t_ii ))
    done
    # subtract one because OPTIND is now one beyond last index handled
    (( --OPTIND ))

    # Determine whether or not we need to add a '--' end-of-options string back
    # into the command line.
    #
    __t_pos=0  # reset
    for __t_posval in "${__t_expanded_command_line[@]}"; do
        (( ++__t_pos ))
        if test "${__t_posval}" = '--'; then
            __t_end_of_options_seen_as_optargs+=( $__t_pos )
        fi
    done

    __t_pos=0  # reset
    for __t_posval in "${MY_COMMAND_LINE_OPTIONS[@]}"; do
        (( ++__t_pos ))
        if test "${__t_posval}" = '--'; then
            __t_end_of_options_seen_unprocessed+=( $__t_pos )
        fi
    done
    unset __t_pos

    t_need_end_of_options_separator_reinstated=false
    if test ${#__t_end_of_options_positions[@]} -gt 0; then

        t_need_cnt=${#__t_end_of_options_positions[@]}

        t_have_cnt=$((   ${#__t_end_of_options_seen_as_optargs[@]}  \
                       + ${#__t_end_of_options_seen_unprocessed[@]} \
                    ))

        # Sanity check
        if test $t_have_cnt = $t_need_cnt; then :; else

            if test $t_have_cnt -gt $t_need_cnt; then
                printf "${PROG} (BUG): invalid state: t_have_cnt (%s) is greater than t_need_cnt (%s); bailing out\n" \
                       "${t_have_cnt}" "${t_need_cnt}" 1>&2
                exit 1
            fi

            t_difference=$(( $t_need_cnt - $t_have_cnt ))

            if test $t_difference -gt 1; then
                printf "${PROG} (BUG): invalid state: difference (%s) of t_need_cnt (%s) and t_have_cnt is greater than 1; bailing out\n" \
                       "${t_difference}" "${t_need_cnt}" "${t_have_cnt}" 1>&2
                exit 1
            fi
        fi

        if test $t_have_cnt -lt $t_need_cnt; then
            t_need_end_of_options_separator_reinstated=true
        fi
    fi

    # if test $# -gt 0; then
    if test ${#MY_COMMAND_LINE_OPTIONS[@]} -gt 0; then

        if $t_need_end_of_options_separator_reinstated; then
            # Our getopts processing was stopped due to the presence of '--',
            # and consumed that positional value. We'll add it back in at the
            # correct location.
            #
            __t_expanded_command_line+=( '--' )
        fi

        # __t_expanded_command_line+=( "$@" )
        # __t_expanded_command_line+=( "${MY_COMMAND_LINE_OPTIONS[@]}" )

        t_target_idx=${#__t_expanded_command_line[@]}
        for t_source_idx in "${!MY_COMMAND_LINE_OPTIONS[@]}"; do
            __t_expanded_command_line[${t_target_idx}]=${MY_COMMAND_LINE_OPTIONS[${t_source_idx}]}

            (( ++t_target_idx ))
        done
    fi

    unset t_need_end_of_options_separator_reinstated
    unset __t_end_of_options_seen_unprocessed
    unset __t_end_of_options_seen_as_optargs
    unset __t_end_of_options_positions

    for tidx in "${!__t_expanded_command_line[@]}"; do
        : $PROG \(trace: $LINENO\): __t_expanded_command_line[${tidx}]: ${__t_expanded_command_line[${tidx}]}
    done

    # echo "${__t_expanded_command_line[@]}"
    # printf '%q ' "${__t_expanded_command_line[@]}"

# AL.DEBUG working here

    # Rather than emit a value on stdout (which requires callers to invoke us
    # in a subshell where we cannot trigger permanantly the useful side-effect
    # of enabling verbose output early on), we will instead update the
    # caller's named array variable in-place with the values we would have
    # otherwise emitted on stdout.
    #
    eval "${__output_array_name}=()"  # empty out
    for t_idx in "${!__t_expanded_command_line[@]}"; do
        eval "${__output_array_name}[${t_idx}]=\"$(printf '%q' "${__t_expanded_command_line[${t_idx}]}")\""
    done

# # DEBUG go
#     # This just allows for inspection of the referenced array as it will
#     # appear to the caller once this function returns.
#     #
#     local __t_arrayref="${__output_array_name}[@]"

#     for tval in "${!__t_arrayref}"; do  # iterating over elements of indirectly referenced array
#         : $PROG \(trace: $LINENO\): one ${__output_array_name} value: $tval
#     done
# # DEBUG end

    return 0  # success

# set -- "${__t_expanded_command_line[@]}"
# if test $? -ne 0; then
#     printf "${PROG} (error): was unable to force use of rewritten (expanded) command line; bailing out\n" 1>&2
#     exit 1
# fi
# : $PROG \(trace: $LINENO\): expanded command line: "$@"

}


# Makes a HTTP HEAD request to the GitHub service to obtain pagination
# information for pulling all /user/repos data in the minimal number of
# service calls (that is, within the service restriction of 100 repos per
# response "page").
#
# Upon success, emits on stdout the number of "pages" that need to be
# requested.
#
# Recall that the first page is one, not zero.
#
f_get_gh_user_repos_pagination_count_or_die () {

    # Pagination: 
    #
    # HTTP/1.1 200 OK
    # ...
    # Link: <https://api.github.com/user/repos?per_page=100&page=2>; rel="next", <https://api.github.com/user/repos?per_page=100&page=4>; rel="last"

    t_head_response=$( curl "${MY_CURL_OPTS[@]}" \
                            --head               \
                            "${MY_GITHUB_REPOS_URL}" \
                       | tr -d '\r' )

    if test $? -ne 0; then
        # Hopefully curl printed something meaningful to stderr here...
        printf "${PROG} (error): was unable to obtain pagination info for repos; bailing out\n" 1>&2
        exit 1
    fi

    # From RFC 7230:
    #
    #     3.1.2.  Status Line
    #
    #        The first line of a response message is the status-line, consisting
    #        of the protocol version, a space (SP), the status code, another
    #        space, a possibly empty textual phrase describing the status code,
    #        and ending with CRLF.
    #
    #          status-line = HTTP-version SP status-code SP reason-phrase CRLF
    #
    #        The status-code element is a 3-digit integer code describing the
    #        result of the server's attempt to understand and satisfy the client's
    #        corresponding request.  The rest of the response message is to be
    #        interpreted in light of the semantics defined for that status code.
    #        See Section 6 of [RFC7231] for information about the semantics of
    #        status codes, including the classes of status code (indicated by the
    #        first digit), the status codes defined by this specification,
    #        considerations for the definition of new status codes, and the IANA
    #        registry.
    #
    #          status-code    = 3DIGIT
    #
    #        The reason-phrase element exists for the sole purpose of providing a
    #        textual description associated with the numeric status code, mostly
    #        out of deference to earlier Internet application protocols that were
    #        more frequently used with interactive text clients.  A client SHOULD
    #        ignore the reason-phrase content.
    #
    #          reason-phrase  = *( HTAB / SP / VCHAR / obs-text )
    #
    # Note that we're following Postel's Prescription to an extent in being
    # lenient about whether or not there is more than a single whitespace
    # token between fields.
    #
    t_http_head_stat_and_label=$(echo "${t_head_response}" | head -n 1 | sed -n -e '/^HTTP[/]/ { s#^HTTP/[^[:space:]]\{1,\}[[:space:]]\{1,\}\([[:digit:]]\{3\}[[:space:]]\{1,\}.*\)#\1#p;q }')
    if test -z "${t_http_head_stat_and_label}"; then
        printf "${PROG} (error): was unable to extract HTTP status code from responses; bailing out\n    Full HTTP response headers:\n%s\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi

    if $DEBUGGING; then
        printf "${PROG} (debug): HTTP status and label for pagination info: %s\n" "${t_http_head_stat_and_label}" 1>&2
    fi

    t_http_head_stat=$(  echo "${t_http_head_stat_and_label}" | sed -e 's#^\([[:digit:]]\{3\}\)[[:space:]]\{1,\}.*#\1#')
    t_http_head_label=$( echo "${t_http_head_stat_and_label}" | sed -e 's#^[[:digit:]]\{3\}[[:space:]]\{1,\}\([[:space:][:alnum:][:punct:]]*\)$#\1#')

    if $DEBUGGING; then
        printf "${PROG} (debug): HTTP status for pagination info: %s\n" "${t_http_head_stat}"  1>&2
        printf "${PROG} (debug): HTTP label for pagination info: %s\n"  "${t_http_head_label}" 1>&2
    fi

    if test -z "${t_http_head_stat}"; then
        printf "${PROG} (error): was unable to determine HTTP status code of pagination info request for repo; bailing out\n" 1>&2
        exit 1
    fi

    # Slice off leading zeros in bogon HTTP response code. Belt AND suspenders...
    #
    t_http_head_stat=$((10#$t_http_head_stat))

    if test $t_http_head_stat -lt 100; then
        # We'll include the full response line to help in troubleshooting. In
        # the worst case scenario we will learn that we mis-parsed it somehow,
        # which is a really a win in the long term.
        printf "${PROG} (error): received bogon HTTP status line with response code less than 100 (\"%s\"); bailing out\n" "${t_http_head_stat_and_label}" 1>&2
        exit 1
    fi

    # Oh hell, if we're gonna check the lower bound, then we're boning it if
    # we don't also check the upper bound...
    if test $t_http_head_stat -gt 599; then
        printf "${PROG} (error): received bogon HTTP status line with response code greater than 599 (\"%s\"); bailing out\n" "${t_http_head_stat_and_label}" 1>&2
        exit 1
    fi

    # So we know that the HTTP status code is somewhere between 100 and 599...

    if test $t_http_head_stat -ge 100 \
    && test $t_http_head_stat -lt 200; then
        printf "${PROG} (error): program does not directly grok HTTP 1xx \"Informational\" status codes; bailing out\n    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi

    if test $t_http_head_stat -ge 300 \
    && test $t_http_head_stat -lt 400; then
        printf "${PROG} (error): program does not directly grok HTTP 3xx \"Redirection\" status codes; bailing out\n"\
"    If you encounter this error, please submit a bug report; real-world need is likely to get it fixed.\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi

    if test $t_http_head_stat -ge 400 \
    && test $t_http_head_stat -lt 500; then
        printf "${PROG} (error): program received a HTTP 4xx \"Client Error\" status codes; bailing out\n"\
"    If you encounter this error, please submit a bug report; it suggests there is a problem with the\n"\
"    way in which the program is formulating requests to the upstream GitHub service.\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi

    if test $t_http_head_stat -ge 500 \
    && test $t_http_head_stat -lt 600; then
        printf "${PROG} (error): program received a HTTP 5xx \"Server Error\" status codes; bailing out\n"\
"    If you encounter this error, it suggests there is a problem with the upstream GitHub service;\n"\
"    please wait a while and try your request later.\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi

    # Internal sanity check
    if test $t_http_head_stat -ge 200 \
    && test $t_http_head_stat -lt 300; then :; else
        printf "${PROG} (bug): internal check failed. Expected that we received a 2xx \"Successful\" HTTP status code, but really have: \"%s\"; bailing out.\n"\
"    If you encounter this error, there is a serious bug with this program; please submit a bug report.\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi

    # So we know that the HTTP status code is somewhere between 200 and 299;
    # we're good (probably).

    # FIXME: This will break if the 'Link:' header content spans multiple
    #        lines (which is legit; see RFC 2616 section 4.2 "Message
    #        Headers").

    # Let's find the 'Link: ' header...
    t_http_head_link=$(echo "${t_head_response}" | grep '^Link:[[:space:]]')
    if test $? -ne 0; then

        # It's not necessarily an error if the 'Link:' header is not
        # present. That will happen for resources that do not require any
        # pagination. So we'll examine the individual exit status codes from
        # our pipeline; if grep exited with status 1, it means the header was
        # not found. If it exited with 2 it indicates an error (such as a
        # malformed regex).
        #
        if test "${PIPESTATUS[0]}" -eq 0 \
        && test "${PIPESTATUS[1]}" -eq 1; then
            # We'll emit 1 as the count of pages needed
            printf "1\n"
            return  # success
        fi

        # Hopefully grep emitted something helpful on stderr already if we're
        # falling through here...

        printf "${PROG} (error): was error while attempting to locate HTTP \"Link:\" header in HEAD response; no pagination data available; bailing out\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi

    # After the 'Link: ' header label, we expect the content to contain a
    # comma-space-separated list of values in the form:
    #
    #     <url>; rel="foo", <url>; rel="bar"
    #
    # Example:
    #
    #     Link: <https://api.github.com/user/repos?per_page=100&page=2>; rel="next", <https://api.github.com/user/repos?per_page=100&page=4>; rel="last"
    #
    # We'll look for the rel="last" entry, which should be present even when
    # it's URL value would be the same as the rel="next" entry. The first
    # 'sed' invocation lifts out the URL from the rel="last" entry, and the
    # second then extracts the number of the last page from the 'page=N'
    # parameter.
    #
    t_last_page_number=$( echo "${t_http_head_link}" \
                          | sed -n -e 's#.*\([<][^>]\{1,\}[>]\)[[:space:]]*[;][^,]*rel="last"#\1#p' \
                          | sed -n -e 's#.*[?&]page=\([[:digit:]]\{1,\}\)[^[:digit:]]#\1#p' )
    if test $? -ne 0; then
        printf "${PROG} (error): was error while attempting to parse last page number from HTTP \"Link:\" header in HEAD response; bailing out\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi
    if test -z "${t_last_page_number}"; then
        printf "${PROG} (error): extracted empty value for last page number from HTTP \"Link:\" header in HEAD response; bailing out\n"\
"    Full HTTP response headers:\n%n\n" \
               "$(echo "${t_head_response}" | sed -e 's/^/        /')" 1>&2
        exit 1
    fi

    printf "%s\n" "${t_last_page_number}"
    return  # success
}



# Note: We do not want to enable 'extdebug' just to get $BASH_ARGV defined, so
# we'll jam the command line options into a global array variable that we can
# manipulate from within shell functions (f_rewrite_command_line_or_die() and
# friends)
#
declare -a MY_COMMAND_LINE_OPTIONS=( "$@" )

if $DEBUGGING; then
    printf "${PROG} (debug): command line options preprocessing: rewriting to expand bundled short-form opts\n" 1>&2
fi
# set -x
# f_rewrite_command_line_or_die
# set -- $( f_rewrite_command_line_or_die )
# if test $? -ne 0; then
#     printf "${PROG} (error): was unable to force use of rewritten (expanded) command line; bailing out\n" 1>&2
#     exit 1
# fi
declare -a MY_COMMAND_LINE_OPTIONS_REWRITTEN=()
f_rewrite_command_line_or_die MY_COMMAND_LINE_OPTIONS_REWRITTEN
: $PROG \(trace: $LINENO\): expanded command line: "$@"
if $DEBUGGING; then
    printf "${PROG} (debug): command line options preprocessing: successfully rewrote to expand bundled short-form opts\n" 1>&2
fi

set -- "${MY_COMMAND_LINE_OPTIONS_REWRITTEN[@]}"

while test $# -gt 0 ; do

    option=$(expr "x$1" : 'x\(--[^=]*\)' \| \
                  "x$1" : 'x\(-.*\)'     \| \
                  "x$1" : 'x\(.*\)')

    optarg=$(expr "x$1" : 'x--[^=]*=\(.*\)' \| \
                  "x$1" : 'x-.\(.*\)')

    case $1 in

        --help | -h )
            # print help message
            f_print_help
            exit 0
            ;;

        --version | -V )
            # print program version info
            f_print_version
            exit 0
            ;;

        --clone-if-missing | -c )
            DO_CLONE_IF_NOT_PRESENT=true
            shift
            ;;

        --upstream-remote-if-missing | -u )
            DO_CREATE_UPSTREAM_REMOTE_IF_NOT_PRESENT=true
            shift
            ;;

        --verbose | -v )
            # Accumulating 'verbose' opt. A single -v opt simply turns
            # BE_VERBOSE on (info level output); two '-v' opts turns on
            # $DEBUGGING (debug level output); three or more '-v' opts turns
            # tracing on. Note that if you intend to turn tracing on, you'll
            # probably want your -v opts to be the first opts on the command
            # line (so they take effect earlier).
            #
            f_maybe_increase_verbosity
            shift
            ;;

        -- ) # Stop option processing
            shift
            break
            ;;

        --* | -* )
            # Unrecognized option
            printf "${PROG} (error): unrecognized option \`%s'\n" "${option}" 1>&2
            f_print_help 1>&2
            exit 1
            ;;

        * ) # Unrecognized non-option

            # We'll treat the first non-option and all remaining arguments as
            # names of git repositories that the user specifically wants to
            # operate on; note that we DO NOT shift off the first, but merely
            # stop processing command line options when we see it.
            break
            ;;
    esac
done

declare -a EXPLICITLY_REQUESTED_REPOS=()

# Any remaining arguments are interpretted as the names of repositories that
# the user specifically wants to operate on.
#
# XXX: We do not currently do anything special to account for the same repo
#      being specified more than once; I'm not yet convinced that we
#      should. If the user tells us to operate on repos "foo bar foo", we'll
#      operate on "foo" twice (though the second will effectively be an
#      elaborate NOOP).
#
while test $# -gt 0 ; do

    _one_repo_name=$1; shift

    if $BE_VERBOSE; then
        printf "${PROG} (info): noting user-specified explicit repo name: \"%s\"\n" "${_one_repo_name}" 1>&2
    fi

    EXPLICITLY_REQUESTED_REPOS+=( "${_one_repo_name}" )
done

for ext_tool in "${NEEDED_EXTERNAL_PROGS[@]}"; do

    t_path=$(builtin type -p "${ext_tool}")
    if test $? -ne 0; then
        printf "${PROG} (error): was unable to locate \"%s\" on PATH; bailing out\n" "${ext_tool}" 1>&2
        exit 1
    fi

    if $DEBUGGING; then
        printf "${PROG} (debug): path to external tool \"%s\": %s\n" "${ext_tool}" "${t_path}" 1>&2
    fi
done


# Refuse to run if we do not recognize the URL as something that will be
# encrypted on the wire. This is intended to help prevent accidentally
# transmitting HTTP Basic Auth credentials in cleartext.
#
re_starts_with_https='^https://'
if test -z "${gl_const_github_api_base_url}"; then
    printf "${PROG} (error): GitHub API base URL is not defined; bailing out\n" 1>&2
    exit 1
fi
if [[ "${gl_const_github_api_base_url}" =~ $re_starts_with_https ]]; then :; else
    printf "${PROG} (error): configured GitHub API base URL (\"%s\") does not start with 'https://'; bailing out\n" "${gl_const_github_api_base_url}" 1>&2
    exit 1
fi
#
re_ends_with_slash='.*[/]$'
if [[ "${gl_const_github_api_base_url}" =~ $re_ends_with_slash ]]; then :; else
    if $BE_VERBOSE; then
        printf "${PROG} (info): configured GitHub API base URL (\"%s\") does not end with a slash; appending slash character\n" "${gl_const_github_api_base_url}" 1>&2
    fi
    gl_const_github_api_base_url="${gl_const_github_api_base_url}/"
    declare -r gl_const_github_api_base_url
    if $BE_VERBOSE; then
        printf "${PROG} (info): configured GitHub API base URL (modified) is now: \"%s\"\n" "${gl_const_github_api_base_url}" 1>&2
    fi
fi
if $BE_VERBOSE; then
    printf "${PROG} (info): configured GitHub API base URL: \"%s\"\n" "${gl_const_github_api_base_url}" 1>&2
fi


re_starts_with_accept='Accept:[[:space:]]'
if test -z "${gl_const_http_accept_github_version}"; then
    printf "${PROG} (error): HTTP 'Accept:' header for GitHub API version is not defined; bailing out\n" 1>&2
    exit 1
fi
if [[ "${gl_const_http_accept_github_version}" =~ $re_starts_with_accept ]]; then :; else
    printf "${PROG} (error): configured HTTP 'Accept:' header (\"%s\") for GitHub API version does not start with 'Accept: '; bailing out\n" "${gl_const_http_accept_github_version}" 1>&2
    exit 1
fi
if $BE_VERBOSE; then
    printf "${PROG} (info): configured HTTP 'Accept:' header for GitHub API version: \"%s\"\n" "${gl_const_http_accept_github_version}" 1>&2
fi


# Note that the gl_const_http_accept_github_version value is known to always
# end with a slash character.
#
# per_page: The GitHub v3 API allows for retrieving results in "page sizes" up
# to 100 (in this case, 100 repositories). If a 'per_page' value greater than
# 100 is specified, then the service silently behaves as if 100 were
# specified. Since we need to slurp down all of the data for our purposes
# here, we specify the maximum page size so we have to make the fewest number
# of remote calls while paging through the results.
#
MY_GITHUB_REPOS_URL="${gl_const_github_api_base_url}user/repos?per_page=100"


# Common global options for use in every 'curl' invocation. Specific
# invocations will require additional options, but such usages should not
# modify this array.
#
declare -a MY_CURL_OPTS=()

# This disables output of curl's progress meter /and/ output of error messages...
MY_CURL_OPTS+=( '--silent' )
# ...but this re-enables output of the error messages.
MY_CURL_OPTS+=( '--show-error' )


# Force use of TLS 1.2. Writing in 2016, all previous versions are known to be
# broken and susceptible to known attacks. Note that the '--tlsv1.2' option
# was added in curl 7.34.0
#
# This is absolutely essential since we're using HTTP Basic Auth (see below).
#
MY_CURL_OPTS+=( '--tlsv1.2' )

# Allow ONLY https, for both the initial request and for redirects
MY_CURL_OPTS+=( '--proto')
MY_CURL_OPTS+=( 'https')
MY_CURL_OPTS+=( '--proto-redir')
MY_CURL_OPTS+=( 'https')


# Tell curl to use HTTP Basic Authentication. This is the curl default, but
# we're explicit about what we expect (and want to avoid any surprises from
# weirdo ~/.curlrc files).
#
# See also: RFC 7617 "The 'Basic' HTTP Authentication Scheme" (2015-09)
#
MY_CURL_OPTS+=( '--basic' )


# User's authentication credentials will be obtained from the user's ~/.netrc
# file. See curl(1) and netrc(5)
#
MY_CURL_OPTS+=( '--netrc'  )

MY_CURL_OPTS+=( '--user-agent' )
MY_CURL_OPTS+=( "$PROG"        )


# Even when we're just making HEAD requests, have curl fail
# MY_CURL_OPTS+=( '--fail' )


# Tell the GitHub service that we're trying to speak v3 of the API. Writing in
# 2016, v3 is the default, but some newer version may become the default in
# the future.
#
MY_CURL_OPTS+=( '--header' )
MY_CURL_OPTS+=( "${gl_const_http_accept_github_version}" )


# We'll build up this multi-line value in memory below. Each line will have
# the form:
#
#     repo_name:repo_full_name:default_branch:is_fork
#
# Example of 4 such lines:
#
#     aas:salewski/aas:master:true
#     abcl:salewski/abcl:master:true
#     abstract-tables:salewski/abstract-tables:master:true
#     ac-nrepl:salewski/ac-nrepl:master:true
#
# The 'is_fork' field will always be either 'true' or 'false', and indicates
# whether or not the repo was forked from another GitHub repository. Where the
# value is 'true', callers know they can make a request to the GitHub API's
# /repos/:owner:repo endpoint to request more comprehensive information about
# the repo that would include a 'parent' object. We return the value here
# because it is also useful to know that such a call need not be made if
# you're only interested in the parent data, or just want to know whether or
# not a parent exists.
#
REPO_DATA_LINES=''

# Pagination: 

# HTTP/1.1 200 OK
# ...
# Link: <https://api.github.com/user/repos?per_page=100&page=2>; rel="next", <https://api.github.com/user/repos?per_page=100&page=4>; rel="last"

# Note that we still obtain info on /all/ repos even if the user has specified
# that we operate only on specific repos (in $EXPLICITLY_REQUESTED_REPOS). If
# the user specified only a couple of repos, then we lose here because we
# techically could query the GitHub service for the info on just those
# specific repos to accomplish our work.  If the user explicitly specifies
# more than a few, though, we're back on solid ground because we can typically
# get the info on all available user repos with fewer than 5 GitHub API calls
# (it is unlikely that a typical GitHub user has more than 500 repos). In any
# event, we do not know which page of the results a particular repo will be
# on, so we need to pull full summary data anyway.
#
MY_TOTAL_REPO_PAGES=$(f_get_gh_user_repos_pagination_count_or_die)
t_cur_page=0
t_keep_going=true
while $t_keep_going; do

    let t_cur_page=$t_cur_page+1

    t_gh_url_for_page=${MY_GITHUB_REPOS_URL}'&page='${t_cur_page}

    if $BE_VERBOSE; then
        printf "${PROG} (info): requesting /user/repos page %s of %s\n" "${t_cur_page}" "${MY_TOTAL_REPO_PAGES}" 1>&2
    fi

    # For now we'll just slurp up all of the repo info into memory; we'll
    # revisit this if needed, but <famous-last-words>we're not expecting to
    # have enough repos that it will be a problem</famous-last-words.
    #
    #     $ jq -r '.[] | .name + ":" + .full_name + ":" + .default_branch + ":" + if (.fork) then "true" else "false" end' < all-repos-per_page-105-001.js | head -n 5
    #     aas:salewski/aas:master:true
    #     abcl:salewski/abcl:master:true
    #     abstract-tables:salewski/abstract-tables:master:true
    #     ac-nrepl:salewski/ac-nrepl:master:true
    #     ack2:salewski/ack2:dev:true
    #
    REPO_DATA_LINES=${REPO_DATA_LINES}\
$'\n'\
$( curl "${MY_CURL_OPTS[@]}" \
        --get                \
        "${t_gh_url_for_page}" \
        | jq -r '.[] | .name + ":" + .full_name + ":" + .default_branch + ":" + if (.fork) then "true" else "false" end' )

    # The newline embedded between our existing and new REPO_DATA_LINES
    # instances is intended to ensure that the concatenation of the two does
    # not join the first line of the new to the last line of the old. It is
    # possible, though, that we may have just introduced a spurious blank
    # line; we'll strip it out if so.
    #
    REPO_DATA_LINES=$(echo "${REPO_DATA_LINES}" | sed -e '/^[[:space:]]*$/d' )
    if test $? -ne 0; then
        printf "${PROG} (error): was unable to strip possible empty line out of REPO_DATA_LINES (working page: %s); bailing out\n" \
               "${t_cur_page}" 1>&2
        exit 1
    fi

    if test $t_cur_page -ge $MY_TOTAL_REPO_PAGES; then
        t_keep_going=false
    fi

done


while IFS=':' read -r repo_name repo_full_name default_branch is_fork; do

    : $PROG \(trace: $LINENO\): repo_name:      "$repo_name"
    : $PROG \(trace: $LINENO\): repo_full_name: "$repo_full_name"
    : $PROG \(trace: $LINENO\): default_branch: "$default_branch"
    : $PROG \(trace: $LINENO\): is_fork:        "$is_fork"

    # Sanity checking
    if test -z "${repo_name}"; then
        printf "${PROG} (BUG): 'repo_name' value is empty; bailing out\n" 1>&2
        exit 1
    fi
    if test -z "${repo_full_name}"; then
        printf "${PROG} (BUG): 'repo_full_name' value is empty; bailing out\n" 1>&2
        exit 1
    fi
    if test -z "${default_branch}"; then
        printf "${PROG} (BUG): 'default_branch' value is empty; bailing out\n" 1>&2
        exit 1
    fi
    if test -z "${is_fork}"; then
        printf "${PROG} (BUG): 'is_fork' value is empty; bailing out\n" 1>&2
        exit 1
    fi
    if   test "${is_fork}" = 'true';  then :
    elif test "${is_fork}" = 'false'; then :
    else
        printf "${PROG} (BUG): invalid value detected for 'is_fork' (\"%s\"); should be either 'true' or 'false'; bailing out\n" \
               "${is_fork}" 1>&2
        exit 1
    fi

    if test "${#EXPLICITLY_REQUESTED_REPOS[@]}" -gt 0; then

        t_repo_is_keeper=false

        for expl_repo_name in "${EXPLICITLY_REQUESTED_REPOS[@]}"; do

            if test "${expl_repo_name}" = "${repo_name}"; then
                t_repo_is_keeper=true
                break;
            fi
        done

        if $t_repo_is_keeper; then :; else

            if $DEBUGGING; then
                printf "${PROG} (debug): repo \"%s\" is not one of those explicitly requested for operation; skipping (okay)\n" \
                       "${repo_name}" 1>&2
            fi
            continue
        fi
    fi

    # If there's a subdirectory beneath the current location with the
    # repository name, then it is probably the git working directory for the
    # project. Note that it is possible to have a project cloned into a
    # directory that does not exactly match the project name, but I don't do
    # that with my own repos.
    #
    if test -d "${repo_name}"; then :; else

        if $DO_CLONE_IF_NOT_PRESENT; then

            if $BE_VERBOSE; then
                printf "${PROG} (info): no subdirectory exists for repo name \"%s\"; --clone-if-missing specified, so will clone repo from GitHub\n" "${repo_name}" 1>&2
            fi

            declare t_v_opts=()
            if $BE_VERBOSE; then t_v_opts+=( '--verbose' ); fi
            if $DEBUGGING;  then t_v_opts+=( '--verbose' ); fi
            git hub "${t_v_opts[@]}" clone "${repo_name}"

            if test $? -ne 0; then
                printf "${PROG} (error): was error while attempting to clone repo \"%s\" from GitHub; bailing out\n" "${repo_name}" 1>&2
                exit 1
            fi

            # Sanity check
            if test -d "${repo_name}"; then :; else
                printf "${PROG} (error): just cloned repo \"%s\", but subdir with that name is not present; bailing out\n" "${repo_name}" 1>&2
                exit 1
            fi
        else
            if $DEBUGGING; then
                printf "${PROG} (debug): no subdirectory named after repo \"%s\"; skipping (okay)\n" "${repo_name}" 1>&2
            fi

            continue
        fi
    fi

    if test -d "${repo_name}/.git"; then :; else
        printf "${PROG} (warning): subdirectory named after repo \"%s\" exists, but is not a git working directory; skipping\n" "${repo_name}" 1>&2
        continue
    fi

    # The main purpose of this program is to 'git fetch upstream', but we know
    # that a repo that is not a fork does not have an 'upstream'.
    #
    # XXX: Note that we're doing this check here (rather than at the top of
    # the loop) to allow for the side effect of cloning GitHub repos if there
    # is no working directory present. This behavior should be considered
    # experimental and subject to change in the future. It happens to be
    # convenient for me to do it this way at the moment, but my gut says we
    # might be better off having a separate tool whose job it is to perform
    # just that task.
    #
    # XXX: You may have other remotes defined, or have a non-github repo that
    # has a remote named 'upstream', but this tool will not operate on
    # them. Our purpose here is only to fetch the 'upstream' repo for GitHub
    # repos.
    #
    if $is_fork; then :; else
        if $BE_VERBOSE; then
            printf "${PROG} (info): repo \"%s\" is not a fork of another GitHub repo, so we do not need to check for an \"upstream\" remote; skipping (okay)\n" "${repo_name}" 1>&2
        fi
        continue
    fi

    unset CDPATH
    (
        set -o pipefail  # not inherited from parent shell

        cd "${repo_name}" || exit 1  # from subshell

        declare -a t_pipestatus_hold

        git remote | grep -q --max-count=1 '^upstream$'

        t_pipestatus_hold=( ${PIPESTATUS[@]} )

        if test "${#t_pipestatus_hold[@]}" -ne 2; then
            # This is only possible if we've broken something above, which I
            # did do during development, so I'm leaving it in.
            printf "${PROG} (error): was error while attempting to determine if repo \"%s\" has an \"upstream\" remote defined; bailing out\n" "${repo_name}" 1>&2
            exit 1
        fi

        if test "${t_pipestatus_hold[0]}" -eq 0 \
        && test "${t_pipestatus_hold[1]}" -eq 0; then

            if $DEBUGGING; then
                printf "${PROG} (debug): working dir for repo \"%s\" has an \"upstream\" remote defined\n" "${repo_name}" 1>&2
            fi
            # Keep going...

        elif test "${t_pipestatus_hold[0]}" -eq 0 \
          && test "${t_pipestatus_hold[1]}" -eq 1; then

            # No 'upstream' remote is defined for this repo. Either it is the
            # user's own project (not a fork of some other project), or the
            # 'upstream' remote just wasn't set up. It should be the latter
            # case, though, because we checked the 'fork' flag from the repo's
            # GitHub metadata.

            if $BE_VERBOSE; then
                printf "${PROG} (info): did not find an \"upstream\" remote configured for repo \"%s\"\n" "${repo_name}" 1>&2
            fi

            if $DO_CREATE_UPSTREAM_REMOTE_IF_NOT_PRESENT; then

# vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv

                if $BE_VERBOSE; then
                    printf "${PROG} (info): '-u' (--upstream-remote-if-missing) option was specified; will attempt to create \"upstream\" git remote for repo \"%s\"\n" "${repo_name}" 1>&2
                fi

                # We will set up (using the git-hub tool) an "upstream" remote
                # that points to the parent.

# FIXME: go
#     I thought git-hub would just add the 'upstream' repo here, but upon
#     closer reading I see that is not the case. We're just doing this inline
#     for now, but it might be a better fit as an enhancement to 'git-hub'.
                # printf "${PROG} (WIP): '--upstream-remote-if-missing' feature not yet fully implemented; bailing out\n" 1>&2
                # exit 1
# FIXME: end

                # declare t_v_opts2=()
                # if $BE_VERBOSE; then t_v_opts2+=( '--verbose' ); fi
                # if $DEBUGGING;  then t_v_opts2+=( '--verbose' ); fi

                # git hub "${t_v_opts2[@]}" clone "${repo_name}"

                # if test $? -ne 0; then
                #     printf "${PROG} (error): was error while attempting to establish the \"upstream\" remote for repo \"%s\" from via 'git hub clone...'; bailing out\n" "${repo_name}" 1>&2
                #     exit 1
                # fi


                # We'll ask the GitHub service if this repo has a "parent",
                # which it should (read as: "will, modulo changes due to
                # timing since we checked") because we've already checked
                # above. If not (won't happen), then there's nothing left to
                # do. Note that we have to make a call to the service
                # inquiring about a specific repo to obtain the parent's
                # 'clone_url'; it is not available in the output of the full
                # list of repos which we've alread obtained. This could be a
                # bit expensive against your rate limit if you have a large
                # number of repos, but if most of those repos are forks it
                # will only be expensive the first time the program is run to
                # update those repos.

                # From the GitHub v3 API:
                #
                #     Get
                #
                #     GET /repos/:owner/:repo
                #     Response
                #
                #     The parent and source objects are present when the
                #     repository is a fork. parent is the repository this
                #     repository was forked from, source is the ultimate source
                #     for the network.

                # Note that the repo_full_name value here has the form
                # 'username/repo_name', so matches the structure of the URL
                # needed.
                #
                t_gh_url_for_this_repo="${gl_const_github_api_base_url}repos/${repo_full_name}"

                if $BE_VERBOSE; then
                    printf "${PROG} (info): querying GitHub service to obtain parent clone url for repo \"%s\"\n" "${repo_name}" 1>&2
                fi

                t_parent_clone_url=$( curl "${MY_CURL_OPTS[@]}" \
                                      --get                \
                                      "${t_gh_url_for_this_repo}" \
                                      | jq -r '.clone_url' )
                if test $? -ne 0; then
                    printf "${PROG} (error): was unable to query GitHub service to obtain clone url for repo \"%s\"; bailing out\n" "${repo_name}" 1>&2
                    exit 1  # from subshell
                fi
                if test -z "${t_parent_clone_url}"; then
                    printf "${PROG} (error): was unable to obtain clone url for repo \"%s\"; bailing out\n" "${repo_name}" 1>&2
                    exit 1  # from subshell
                fi

                if $BE_VERBOSE; then
                    printf "${PROG} (info): setting up \"upstream\" remote for repo \"%s\" to: %s\n" "${repo_name}" "${t_parent_clone_url}" 1>&2
                fi

                git remote add upstream "${t_parent_clone_url}"

                if test $? -ne 0; then
                    printf "${PROG} (error): was unable to establish \"upstream\" remote for repo \"%s\"; bailing out\n" "${repo_name}" 1>&2
                    exit 1
                fi

                if $DEBUGGING; then
                    printf "${PROG} (info): successfully set up \"upstream\" remote for repo \"%s\" to: %s\n" "${repo_name}" "${t_parent_clone_url}" 1>&2
                fi

# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
            else
                printf "${PROG} (warning): no remote named \"upstream\" defined for repo \"%s\"; skipping (okay)\n" "${repo_name}" 1>&2
                exit 0  # from subshell
            fi

        else

# FIXME: Introduce a "keep going" feature to avoid bailing out here
# FIXME: Introduce a "skip repo" feature to allow caller to exclude processing of some repo subidrs

            printf "${PROG} (error): was error while attempting to determine if repo \"%s\" has an \"upstream\" remote defined; bailing out\n" "${repo_name}" 1>&2
            exit 1
        fi

        if $BE_VERBOSE; then
            printf "${PROG} (info): invoking 'git fetch upstream' for repo \"%s\"\n" "${repo_name}" 1>&2
        fi

        git fetch upstream
        if test $? -ne 0; then
            printf "${PROG} (error): was error while attempting to 'git fetch upstream' for repo \"%s\"; bailing out\n" "${repo_name}" 1>&2
            exit 1
        fi

        if $DEBUGGING; then
            printf "${PROG} (debug): successfully invoked 'git fetch upstream' for repo \"%s\"\n" "${repo_name}" 1>&2
        fi
    )

    if test $? -ne 0; then
# FIXME: see above note about introducing a "keep going" feature

        # We're expecting that an error message would have already been printed by the subshell
        exit $?
    fi

done < <(echo "$REPO_DATA_LINES")

if $BE_VERBOSE; then
    printf "${PROG} (info): completed successfully\n" 1>&2
fi
